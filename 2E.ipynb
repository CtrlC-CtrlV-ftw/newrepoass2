{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with respect to W1: \n",
      " [[-0.10768404 -0.17229447]\n",
      " [ 0.          0.        ]] \n",
      "\n",
      "Gradient with respect to W3: \n",
      " [[-0.6729851  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    # Apply the ReLU activation function element-wise\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def heaviside(x):\n",
    "    # Apply the Heaviside step function element-wise\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def forward_pass(X, W1, W3):\n",
    "    # Compute the input to the hidden layer\n",
    "    X1 = np.dot(X, W1)\n",
    "    \n",
    "    # Apply ReLU activation to the hidden layer\n",
    "    X2 = relu(X1)\n",
    "    \n",
    "    # Compute the output of the network\n",
    "    X3 = np.dot(X2, W3)\n",
    "    \n",
    "    return X1, X2, X3\n",
    "\n",
    "def backward_pass(X, y, W1, W3, X1, X2, X3):\n",
    "    # Compute the error gradient at the output layer\n",
    "    dE_dX3 = -(y - X3) \n",
    "\n",
    "    # Compute the gradient of the loss with respect to the output layer weights\n",
    "    dE_dW3 = dE_dX3 @ X2\n",
    "\n",
    "    # Propagate the error gradient back to the hidden layer\n",
    "    dE_dX2 = W3 @ dE_dX3\n",
    "\n",
    "    # Compute the error gradient at the input of the hidden layer\n",
    "    dE_dX1 = heaviside(X2).T * dE_dX2\n",
    "    \n",
    "    # Compute the gradient of the loss with respect to the hidden layer weights\n",
    "    dE_dW1 = dE_dX1 @ X \n",
    "\n",
    "    return dE_dW1, dE_dW3\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0.5, 0.8]])  # Input data\n",
    "y = np.array([[1.0]])  # Ground truth labels\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize weights randomly\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Perform forward pass\n",
    "X1, X2, X3 = forward_pass(X, W1, W2)\n",
    "\n",
    "# Perform backward pass\n",
    "dE_dW1, dE_dW3 = backward_pass(X, y, W1, W2, X1, X2, X3)\n",
    "\n",
    "print(f\"Gradient with respect to W1: \\n {dE_dW1} \\n\")\n",
    "print(f\"Gradient with respect to W3: \\n {dE_dW3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Mean Squared Error: 39214.2029\n",
      "Epoch [20/100], Mean Squared Error: 39214.2029\n",
      "Epoch [30/100], Mean Squared Error: 39214.2029\n",
      "Epoch [40/100], Mean Squared Error: 39214.2029\n",
      "Epoch [50/100], Mean Squared Error: 39214.2029\n",
      "Epoch [60/100], Mean Squared Error: 39214.2029\n",
      "Epoch [70/100], Mean Squared Error: 39214.2029\n",
      "Epoch [80/100], Mean Squared Error: 39214.2029\n",
      "Epoch [90/100], Mean Squared Error: 39214.2029\n",
      "Epoch [100/100], Mean Squared Error: 39214.2029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def relu(x):\n",
    "    # Apply the ReLU activation function element-wise\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def heaviside(x):\n",
    "    # Apply the Heaviside step function element-wise\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def forward_pass(X, W1, W2):\n",
    "    # Compute the input to the hidden layer\n",
    "    X1 = np.dot(X, W1)\n",
    "    \n",
    "    # Apply ReLU activation to the hidden layer\n",
    "    X2 = relu(X1)\n",
    "    \n",
    "    # Compute the output of the network\n",
    "    X3 = np.dot(X2, W2)\n",
    "    \n",
    "    return X1, X2, X3\n",
    "\n",
    "def backward_pass(X, y, W1, W2, X1, X2, X3, learning_rate):\n",
    "    # Compute the error gradient at the output layer\n",
    "    dE_dX3 = -(y - X3) \n",
    "\n",
    "    # Compute the gradient of the loss with respect to the output layer weights\n",
    "    dE_dW2 = np.dot(X2.T, dE_dX3)\n",
    "\n",
    "    # Propagate the error gradient back to the hidden layer\n",
    "    dE_dX2 = np.dot(dE_dX3, W2.T)\n",
    "\n",
    "    # Compute the error gradient at the input of the hidden layer\n",
    "    dE_dX1 = heaviside(X2) * dE_dX2\n",
    "    \n",
    "    # Compute the gradient of the loss with respect to the hidden layer weights\n",
    "    dE_dW1 = np.dot(X.T, dE_dX1)\n",
    "\n",
    "    # Update the weights using the gradients and learning rate\n",
    "    W1 -= learning_rate * dE_dW1\n",
    "    W2 -= learning_rate * dE_dW2\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "# Load the training data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Extract the input features and target variable\n",
    "X = training_data[['height', 'wave_length']].values\n",
    "y = training_data['speed'].values.reshape(-1, 1)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize weights randomly\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(X)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X[i].reshape(1, -1)\n",
    "        y_sample = y[i].reshape(1, -1)\n",
    "        \n",
    "        # Perform forward pass\n",
    "        X1, X2, X3 = forward_pass(X_sample, W1, W2)\n",
    "        \n",
    "        # Perform backward pass and update weights\n",
    "        W1, W2 = backward_pass(X_sample, y_sample, W1, W2, X1, X2, X3, learning_rate)\n",
    "    \n",
    "    # Print the mean squared error every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        y_pred = forward_pass(X, W1, W2)[-1]\n",
    "        mse = np.mean((y - y_pred)**2)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [20/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [30/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [40/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [50/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [60/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [70/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [80/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [90/100], Mean Squared Error: 39107.2715908021\n",
      "Epoch [100/100], Mean Squared Error: 39107.2715908021\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Extract the input features and target variable\n",
    "X = training_data[['height', 'wave_length']].values\n",
    "y = training_data['speed'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Initialize weights randomly\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training data\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X_train[i].reshape(1, -1)\n",
    "        y_sample = y_train[i].reshape(1, -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        hidden_layer = np.maximum(0, np.dot(X_sample, W1))\n",
    "        output = np.dot(hidden_layer, W2)\n",
    "        \n",
    "        # Backward pass\n",
    "        output_delta = output - y_sample\n",
    "        hidden_error = np.dot(output_delta, W2.T)\n",
    "        hidden_delta = hidden_error * (hidden_layer > 0)\n",
    "        \n",
    "        # Update weights\n",
    "        W2 -= learning_rate * np.dot(hidden_layer.T, output_delta)\n",
    "        W1 -= learning_rate * np.dot(X_sample.T, hidden_delta)\n",
    "    \n",
    "    # Print the mean squared error every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        hidden_layer = np.maximum(0, np.dot(X_test, W1))\n",
    "        y_pred = np.dot(hidden_layer, W2)\n",
    "        mse = np.mean((y_test - y_pred)**2)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Mean Squared Error: {mse:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Mean Squared Error: 39107.2716\n",
      "Epoch [20/100], Mean Squared Error: 39107.2716\n",
      "Epoch [30/100], Mean Squared Error: 39107.2716\n",
      "Epoch [40/100], Mean Squared Error: 39107.2716\n",
      "Epoch [50/100], Mean Squared Error: 39107.2716\n",
      "Epoch [60/100], Mean Squared Error: 39107.2716\n",
      "Epoch [70/100], Mean Squared Error: 39107.2716\n",
      "Epoch [80/100], Mean Squared Error: 39107.2716\n",
      "Epoch [90/100], Mean Squared Error: 39107.2716\n",
      "Epoch [100/100], Mean Squared Error: 39107.2716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Extract the input features and target variable\n",
    "X = training_data[['height', 'wave_length']].values\n",
    "y = training_data['speed'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Initialize weights randomly\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training data\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X_train[i].reshape(1, -1)\n",
    "        y_sample = y_train[i].reshape(1, -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        X1 = np.dot(X_sample, W1)\n",
    "        X2 = np.maximum(0, X1)\n",
    "        X3 = np.dot(X2, W2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dE_dX3 = X3 - y_sample\n",
    "        dE_dW2 = np.dot(X2.T, dE_dX3)\n",
    "        dE_dX2 = np.dot(dE_dX3, W2.T)\n",
    "        dE_dX1 = dE_dX2 * (X1 > 0)\n",
    "        dE_dW1 = np.dot(X_sample.T, dE_dX1)\n",
    "        \n",
    "        # Update weights\n",
    "        W2 -= learning_rate * dE_dW2\n",
    "        W1 -= learning_rate * dE_dW1\n",
    "    \n",
    "    # Print the mean squared error every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        X1_test = np.dot(X_test, W1)\n",
    "        X2_test = np.maximum(0, X1_test)\n",
    "        y_pred = np.dot(X2_test, W2)\n",
    "        mse = np.mean((y_test - y_pred)**2)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Mean Squared Error: 1.6388\n",
      "Epoch [20/1000], Mean Squared Error: 1.6274\n",
      "Epoch [30/1000], Mean Squared Error: 1.6287\n",
      "Epoch [40/1000], Mean Squared Error: 1.6254\n",
      "Epoch [50/1000], Mean Squared Error: 1.6211\n",
      "Epoch [60/1000], Mean Squared Error: 1.6317\n",
      "Epoch [70/1000], Mean Squared Error: 1.6960\n",
      "Epoch [80/1000], Mean Squared Error: 1.6139\n",
      "Epoch [90/1000], Mean Squared Error: 1.6487\n",
      "Epoch [100/1000], Mean Squared Error: 1.7220\n",
      "Epoch [110/1000], Mean Squared Error: 1.6473\n",
      "Epoch [120/1000], Mean Squared Error: 1.6979\n",
      "Epoch [130/1000], Mean Squared Error: 2.1043\n",
      "Epoch [140/1000], Mean Squared Error: 1.6533\n",
      "Epoch [150/1000], Mean Squared Error: 1.6142\n",
      "Epoch [160/1000], Mean Squared Error: 1.6547\n",
      "Epoch [170/1000], Mean Squared Error: 1.6145\n",
      "Epoch [180/1000], Mean Squared Error: 1.6609\n",
      "Epoch [190/1000], Mean Squared Error: 1.7375\n",
      "Epoch [200/1000], Mean Squared Error: 1.6375\n",
      "Epoch [210/1000], Mean Squared Error: 1.6270\n",
      "Epoch [220/1000], Mean Squared Error: 1.6490\n",
      "Epoch [230/1000], Mean Squared Error: 1.6401\n",
      "Epoch [240/1000], Mean Squared Error: 1.6713\n",
      "Epoch [250/1000], Mean Squared Error: 1.8017\n",
      "Epoch [260/1000], Mean Squared Error: 1.7213\n",
      "Epoch [270/1000], Mean Squared Error: 1.7168\n",
      "Epoch [280/1000], Mean Squared Error: 1.6657\n",
      "Epoch [290/1000], Mean Squared Error: 1.6549\n",
      "Epoch [300/1000], Mean Squared Error: 1.6678\n",
      "Epoch [310/1000], Mean Squared Error: 1.6784\n",
      "Epoch [320/1000], Mean Squared Error: 1.7717\n",
      "Epoch [330/1000], Mean Squared Error: 1.6756\n",
      "Epoch [340/1000], Mean Squared Error: 1.6120\n",
      "Epoch [350/1000], Mean Squared Error: 1.7384\n",
      "Epoch [360/1000], Mean Squared Error: 1.6828\n",
      "Epoch [370/1000], Mean Squared Error: 1.6161\n",
      "Epoch [380/1000], Mean Squared Error: 1.8637\n",
      "Epoch [390/1000], Mean Squared Error: 2.0334\n",
      "Epoch [400/1000], Mean Squared Error: 1.6723\n",
      "Epoch [410/1000], Mean Squared Error: 1.6622\n",
      "Epoch [420/1000], Mean Squared Error: 1.6740\n",
      "Epoch [430/1000], Mean Squared Error: 1.6935\n",
      "Epoch [440/1000], Mean Squared Error: 1.7128\n",
      "Epoch [450/1000], Mean Squared Error: 1.6155\n",
      "Epoch [460/1000], Mean Squared Error: 1.7075\n",
      "Epoch [470/1000], Mean Squared Error: 1.6651\n",
      "Epoch [480/1000], Mean Squared Error: 1.6479\n",
      "Epoch [490/1000], Mean Squared Error: 1.6452\n",
      "Epoch [500/1000], Mean Squared Error: 1.6359\n",
      "Epoch [510/1000], Mean Squared Error: 1.6657\n",
      "Epoch [520/1000], Mean Squared Error: 1.8493\n",
      "Epoch [530/1000], Mean Squared Error: 1.7194\n",
      "Epoch [540/1000], Mean Squared Error: 1.6753\n",
      "Epoch [550/1000], Mean Squared Error: 1.6374\n",
      "Epoch [560/1000], Mean Squared Error: 1.7910\n",
      "Epoch [570/1000], Mean Squared Error: 1.6105\n",
      "Epoch [580/1000], Mean Squared Error: 1.6083\n",
      "Epoch [590/1000], Mean Squared Error: 1.6609\n",
      "Epoch [600/1000], Mean Squared Error: 1.7953\n",
      "Epoch [610/1000], Mean Squared Error: 1.6526\n",
      "Epoch [620/1000], Mean Squared Error: 1.8165\n",
      "Epoch [630/1000], Mean Squared Error: 1.6121\n",
      "Epoch [640/1000], Mean Squared Error: 1.6330\n",
      "Epoch [650/1000], Mean Squared Error: 1.6776\n",
      "Epoch [660/1000], Mean Squared Error: 1.7087\n",
      "Epoch [670/1000], Mean Squared Error: 1.6347\n",
      "Epoch [680/1000], Mean Squared Error: 1.6165\n",
      "Epoch [690/1000], Mean Squared Error: 1.9182\n",
      "Epoch [700/1000], Mean Squared Error: 1.6756\n",
      "Epoch [710/1000], Mean Squared Error: 1.6971\n",
      "Epoch [720/1000], Mean Squared Error: 1.6247\n",
      "Epoch [730/1000], Mean Squared Error: 1.6159\n",
      "Epoch [740/1000], Mean Squared Error: 1.7534\n",
      "Epoch [750/1000], Mean Squared Error: 1.6832\n",
      "Epoch [760/1000], Mean Squared Error: 1.6153\n",
      "Epoch [770/1000], Mean Squared Error: 1.6231\n",
      "Epoch [780/1000], Mean Squared Error: 1.6425\n",
      "Epoch [790/1000], Mean Squared Error: 1.6284\n",
      "Epoch [800/1000], Mean Squared Error: 1.6516\n",
      "Epoch [810/1000], Mean Squared Error: 1.6883\n",
      "Epoch [820/1000], Mean Squared Error: 1.6238\n",
      "Epoch [830/1000], Mean Squared Error: 1.7878\n",
      "Epoch [840/1000], Mean Squared Error: 1.6371\n",
      "Epoch [850/1000], Mean Squared Error: 1.8612\n",
      "Epoch [860/1000], Mean Squared Error: 1.7277\n",
      "Epoch [870/1000], Mean Squared Error: 1.6524\n",
      "Epoch [880/1000], Mean Squared Error: 1.6532\n",
      "Epoch [890/1000], Mean Squared Error: 1.6168\n",
      "Epoch [900/1000], Mean Squared Error: 1.7002\n",
      "Epoch [910/1000], Mean Squared Error: 1.7527\n",
      "Epoch [920/1000], Mean Squared Error: 2.0181\n",
      "Epoch [930/1000], Mean Squared Error: 1.6891\n",
      "Epoch [940/1000], Mean Squared Error: 1.6370\n",
      "Epoch [950/1000], Mean Squared Error: 1.6881\n",
      "Epoch [960/1000], Mean Squared Error: 1.8166\n",
      "Epoch [970/1000], Mean Squared Error: 1.6187\n",
      "Epoch [980/1000], Mean Squared Error: 1.6275\n",
      "Epoch [990/1000], Mean Squared Error: 1.7275\n",
      "Epoch [1000/1000], Mean Squared Error: 1.7612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Extract the input features (MedInc and AveRooms) and target variable (MedHouseVal)\n",
    "X = california.data[:, [0, 5]]  # MedInc: Median income, AveRooms: Average number of rooms\n",
    "y = california.target.reshape(-1, 1)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize weights randomly\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training data\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X_train[i].reshape(1, -1)\n",
    "        y_sample = y_train[i].reshape(1, -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        X1 = np.dot(X_sample, W1)\n",
    "        X2 = np.maximum(0, X1)\n",
    "        X3 = np.dot(X2, W2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dE_dX3 = X3 - y_sample\n",
    "        dE_dW2 = np.dot(X2.T, dE_dX3)\n",
    "        dE_dX2 = np.dot(dE_dX3, W2.T)\n",
    "        dE_dX1 = dE_dX2 * (X1 > 0)\n",
    "        dE_dW1 = np.dot(X_sample.T, dE_dX1)\n",
    "        \n",
    "        # Update weights\n",
    "        W2 -= learning_rate * dE_dW2\n",
    "        W1 -= learning_rate * dE_dW1\n",
    "    \n",
    "    # Print the mean squared error every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        X1_test = np.dot(X_test, W1)\n",
    "        X2_test = np.maximum(0, X1_test)\n",
    "        y_pred = np.dot(X2_test, W2)\n",
    "        mse = np.mean((y_test - y_pred)**2)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([305, 760, 110, 706, 278,  57, 487, 782, 289, 156,\\n       ...\\n       405, 203, 609, 746, 453, 311, 749, 565, 206, 301],\\n      dtype='int64', length=800)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Shuffle training data\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(X_train))\n\u001b[0;32m---> 38\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m y_train[indices]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# Get a single training sample\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([305, 760, 110, 706, 278,  57, 487, 782, 289, 156,\\n       ...\\n       405, 203, 609, 746, 453, 311, 749, 565, 206, 301],\\n      dtype='int64', length=800)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "g = 9.80665  # Gravitational acceleration\n",
    "\n",
    "# Compute dimensionally homogeneous and normalized inputs/output\n",
    "c4 = training_data['speed']**4\n",
    "training_data['g2h2_c4'] = (g**2 * training_data['height']**2) / c4\n",
    "training_data['g2hl_c4'] = (g**2 * training_data['height'] * training_data['wave_length']) / c4\n",
    "X = training_data[[\"g2h2_c4\", \"g2hl_c4\"]].values\n",
    "y = (c4 / c4).values.reshape(-1, 1)  # Normalized target (always 1)\n",
    "\n",
    "X = training_data[['height', 'wave_length']]\n",
    "y = training_data.speed.values.reshape(-1, 1) \n",
    "\n",
    "# Split data (80/20)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Network parameters\n",
    "input_dim, hidden_dim, output_dim = 2, 2, 1\n",
    "\n",
    "# Initialize weights\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Learning rate and epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle training data\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X_train[i].reshape(1, -1)\n",
    "        y_sample = y_train[i].reshape(1, -1)\n",
    "\n",
    "        # Forward pass\n",
    "        X1 = np.dot(X_sample, W1)\n",
    "        X2 = np.maximum(0, X1)  # ReLU activation\n",
    "        X3 = np.dot(X2, W2)\n",
    "\n",
    "        # Backward pass\n",
    "        dE_dX3 = X3 - y_sample\n",
    "        dE_dW2 = np.dot(X2.T, dE_dX3)\n",
    "        dE_dX2 = np.dot(dE_dX3, W2.T)\n",
    "        dE_dX1 = dE_dX2 * (X1 > 0)\n",
    "        dE_dW1 = np.dot(X_sample.T, dE_dX1)\n",
    "\n",
    "        # Update weights\n",
    "        W2 -= learning_rate * dE_dW2\n",
    "        W1 -= learning_rate * dE_dW1\n",
    "\n",
    "    # Calculate and print MSE for both training and testing sets\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # Training MSE\n",
    "        X1_train = np.dot(X_train, W1)\n",
    "        X2_train = np.maximum(0, X1_train)\n",
    "        y_pred_train = np.dot(X2_train, W2)\n",
    "        mse_train = np.mean((y_train - y_pred_train)**2)\n",
    "\n",
    "        # Testing MSE\n",
    "        X1_test = np.dot(X_test, W1)\n",
    "        X2_test = np.maximum(0, X1_test)\n",
    "        y_pred_test = np.dot(X2_test, W2)\n",
    "        mse_test = np.mean((y_test - y_pred_test)**2)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train MSE: {mse_train:.4f}, Test MSE: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [20/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [30/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [40/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [50/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [60/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [70/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [80/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [90/100], Train MSE: 36034543881493823488.0000\n",
      "Epoch [100/100], Train MSE: 36034543881493823488.0000\n",
      "Test Mean Squared Error: 36620836487887699968.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def relu(x):\n",
    "    # Apply the ReLU activation function element-wise\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def heaviside(x):\n",
    "    # Apply the Heaviside step function element-wise\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def forward_pass(X, W1, W2):\n",
    "    # Compute the input to the hidden layer\n",
    "    X1 = np.dot(X, W1)\n",
    "    \n",
    "    # Apply ReLU activation to the hidden layer\n",
    "    X2 = relu(X1)\n",
    "    \n",
    "    # Compute the output of the network\n",
    "    X3 = np.dot(X2, W2)\n",
    "    \n",
    "    return X1, X2, X3\n",
    "\n",
    "def backward_pass(X, y, W1, W2, X1, X2, X3, learning_rate):\n",
    "    # Compute the error gradient at the output layer\n",
    "    dE_dX3 = -(y - X3) \n",
    "\n",
    "    # Compute the gradient of the loss with respect to the output layer weights\n",
    "    dE_dW2 = np.dot(X2.T, dE_dX3)\n",
    "\n",
    "    # Propagate the error gradient back to the hidden layer\n",
    "    dE_dX2 = np.dot(dE_dX3, W2.T)\n",
    "\n",
    "    # Compute the error gradient at the input of the hidden layer\n",
    "    dE_dX1 = heaviside(X2) * dE_dX2\n",
    "    \n",
    "    # Compute the gradient of the loss with respect to the hidden layer weights\n",
    "    dE_dW1 = np.dot(X.T, dE_dX1)\n",
    "\n",
    "    # Update the weights using the gradients and learning rate\n",
    "    W1 -= learning_rate * dE_dW1\n",
    "    W2 -= learning_rate * dE_dW2\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "# Load the training data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Define gravitational acceleration\n",
    "g = 9.80665\n",
    "\n",
    "# Compute new variables based on the given formulas\n",
    "g2h2 = g**2 * training_data['height']**2\n",
    "g2hl = g**2 * training_data['height'] * training_data['wave_length']\n",
    "c4 = training_data['speed']**4\n",
    "\n",
    "# Create a new DataFrame with the dimensionally homogeneous inputs and output\n",
    "data = pd.DataFrame({'g2h2': g2h2, 'g2hl': g2hl, 'c4': c4})\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "train_data = data.sample(frac=0.8, random_state=42)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "# Extract the input features and target variable for training\n",
    "X_train = train_data[['g2h2', 'g2hl']].values\n",
    "y_train = train_data['c4'].values.reshape(-1, 1)\n",
    "\n",
    "# Extract the input features and target variable for testing\n",
    "X_test = test_data[['g2h2', 'g2hl']].values\n",
    "y_test = test_data['c4'].values.reshape(-1, 1)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize weights randomly\n",
    "W1 = np.random.randn(input_dim, hidden_dim)\n",
    "W2 = np.random.randn(hidden_dim, output_dim)\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        # Get a single training sample\n",
    "        X_sample = X_train[i].reshape(1, -1)\n",
    "        y_sample = y_train[i].reshape(1, -1)\n",
    "        \n",
    "        # Perform forward pass\n",
    "        X1, X2, X3 = forward_pass(X_sample, W1, W2)\n",
    "        \n",
    "        # Perform backward pass and update weights\n",
    "        W1, W2 = backward_pass(X_sample, y_sample, W1, W2, X1, X2, X3, learning_rate)\n",
    "    \n",
    "    # Print the mean squared error for training data every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        y_pred_train = forward_pass(X_train, W1, W2)[-1]\n",
    "        mse_train = np.mean((y_train - y_pred_train)**2)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train MSE: {mse_train:.4f}\")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred_test = forward_pass(X_test, W1, W2)[-1]\n",
    "mse_test = np.mean((y_test - y_pred_test)**2)\n",
    "print(f\"Test Mean Squared Error: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working but not according to addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/10000], Loss: 39214.2029\n",
      "Epoch [2000/10000], Loss: 39214.2029\n",
      "Epoch [3000/10000], Loss: 39214.2029\n",
      "Epoch [4000/10000], Loss: 39214.2029\n",
      "Epoch [5000/10000], Loss: 39214.2029\n",
      "Epoch [6000/10000], Loss: 39214.2029\n",
      "Epoch [7000/10000], Loss: 39214.2029\n",
      "Epoch [8000/10000], Loss: 39214.2029\n",
      "Epoch [9000/10000], Loss: 39214.2029\n",
      "Epoch [10000/10000], Loss: 39214.2029\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2 / input_size)\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2 / hidden_size)\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1)\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = self.z2 - y\n",
    "        dLoss_dW2 = np.dot(self.a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.W2.T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (self.a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "\n",
    "        self.W2 -= learning_rate * dLoss_dW2 \n",
    "        self.W1 -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X, y, num_epochs, learning_rate):\n",
    "        loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = np.mean((output - y) ** 2)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Extract input features (height and wave_length) and target variable (speed)\n",
    "X = data[['height', 'wave_length']].values\n",
    "y = data['speed'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "loss_history = network.train(X, y, num_epochs, learning_rate)\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c^4 = S(g^2h^2, g^2h\\lambda)$ ---------- $(m^4/s^4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000], Train Loss: 443.7136119706, Val Loss: 130656.9649563681\n",
      "Epoch [2000/100000], Train Loss: 16.2732804542, Val Loss: 70048.5018583734\n",
      "Epoch [3000/100000], Train Loss: 30.7279853725, Val Loss: 42683.1417614233\n",
      "Epoch [4000/100000], Train Loss: 376459.0781334605, Val Loss: 28090.7566997325\n",
      "Epoch [5000/100000], Train Loss: 4.7523854469, Val Loss: 19441.9425591678\n",
      "Epoch [6000/100000], Train Loss: 361.4101693894, Val Loss: 13931.3477185638\n",
      "Epoch [7000/100000], Train Loss: 26749.2365601626, Val Loss: 10233.4798093357\n",
      "Epoch [8000/100000], Train Loss: 1.4825908864, Val Loss: 7655.1876352495\n",
      "Epoch [9000/100000], Train Loss: 3939.5105419735, Val Loss: 5804.8577610591\n",
      "Epoch [10000/100000], Train Loss: 307.9064359092, Val Loss: 4447.3199790761\n",
      "Epoch [11000/100000], Train Loss: 0.9931816849, Val Loss: 3434.2085420802\n",
      "Epoch [12000/100000], Train Loss: 0.7855014320, Val Loss: 2668.0487429188\n",
      "Epoch [13000/100000], Train Loss: 2337.1544597176, Val Loss: 2082.6108467869\n",
      "Epoch [14000/100000], Train Loss: 2452.1135409028, Val Loss: 1631.6162557510\n",
      "Epoch [15000/100000], Train Loss: 83.8824132350, Val Loss: 1281.9639418754\n",
      "Epoch [16000/100000], Train Loss: 8.2592871612, Val Loss: 1009.5141856827\n",
      "Epoch [17000/100000], Train Loss: 0.7986052660, Val Loss: 796.3774118777\n",
      "Epoch [18000/100000], Train Loss: 1.1748238243, Val Loss: 629.1191718174\n",
      "Epoch [19000/100000], Train Loss: 23.1823784264, Val Loss: 497.5404664041\n",
      "Epoch [20000/100000], Train Loss: 439.3798119465, Val Loss: 393.8295836326\n",
      "Epoch [21000/100000], Train Loss: 1.8860464643, Val Loss: 311.9600570558\n",
      "Epoch [22000/100000], Train Loss: 1.5288225343, Val Loss: 247.2554980550\n",
      "Epoch [23000/100000], Train Loss: 0.9335906112, Val Loss: 196.0700302181\n",
      "Epoch [24000/100000], Train Loss: 0.8969007029, Val Loss: 155.5504599126\n",
      "Epoch [25000/100000], Train Loss: 72386.3559842013, Val Loss: 123.4571447818\n",
      "Epoch [26000/100000], Train Loss: 1.2322587610, Val Loss: 98.0278143485\n",
      "Epoch [27000/100000], Train Loss: 0.9100037347, Val Loss: 77.8731312010\n",
      "Epoch [28000/100000], Train Loss: 1.0094410840, Val Loss: 61.8960961474\n",
      "Epoch [29000/100000], Train Loss: 0.9166859094, Val Loss: 49.2294838529\n",
      "Epoch [30000/100000], Train Loss: 0.9415565080, Val Loss: 39.1870587791\n",
      "Epoch [31000/100000], Train Loss: 19.8332946566, Val Loss: 31.2253934249\n",
      "Epoch [32000/100000], Train Loss: 327.6752420309, Val Loss: 24.9138988621\n",
      "Epoch [33000/100000], Train Loss: 1.1093362380, Val Loss: 19.9112405855\n",
      "Epoch [34000/100000], Train Loss: 0.9520928504, Val Loss: 15.9467452188\n",
      "Epoch [35000/100000], Train Loss: 163.8819187533, Val Loss: 12.8057182256\n",
      "Epoch [36000/100000], Train Loss: 0.9458342917, Val Loss: 10.3178362264\n",
      "Epoch [37000/100000], Train Loss: 0.9170532648, Val Loss: 8.3479601185\n",
      "Epoch [38000/100000], Train Loss: 0.9524856840, Val Loss: 6.7888600714\n",
      "Epoch [39000/100000], Train Loss: 0.9745051494, Val Loss: 5.5554494811\n",
      "Epoch [40000/100000], Train Loss: 0.9779595962, Val Loss: 4.5802132528\n",
      "Epoch [41000/100000], Train Loss: 0.9651496163, Val Loss: 3.8095817955\n",
      "Epoch [42000/100000], Train Loss: 0.9861530965, Val Loss: 3.2010539917\n",
      "Epoch [43000/100000], Train Loss: 0.9723637745, Val Loss: 2.7209140585\n",
      "Epoch [44000/100000], Train Loss: 0.9928437261, Val Loss: 2.3424194411\n",
      "Epoch [45000/100000], Train Loss: 0.9654773383, Val Loss: 2.0443622744\n",
      "Epoch [46000/100000], Train Loss: 0.9860151947, Val Loss: 1.8099274398\n",
      "Epoch [47000/100000], Train Loss: 0.9957969448, Val Loss: 1.6257859670\n",
      "Epoch [48000/100000], Train Loss: 0.9563538356, Val Loss: 1.4813752333\n",
      "Epoch [49000/100000], Train Loss: 0.9871642834, Val Loss: 1.3683275378\n",
      "Epoch [50000/100000], Train Loss: 0.9919340094, Val Loss: 1.2800164303\n",
      "Epoch [51000/100000], Train Loss: 0.9798599266, Val Loss: 1.2111965680\n",
      "Epoch [52000/100000], Train Loss: 0.9690986800, Val Loss: 1.1577178471\n",
      "Epoch [53000/100000], Train Loss: 0.9746544471, Val Loss: 1.1162984872\n",
      "Epoch [54000/100000], Train Loss: 2.6327077872, Val Loss: 1.0843449568\n",
      "Epoch [55000/100000], Train Loss: 0.9920124927, Val Loss: 1.0598090622\n",
      "Epoch [56000/100000], Train Loss: 0.9893436262, Val Loss: 1.0410745685\n",
      "Epoch [57000/100000], Train Loss: 0.9947842623, Val Loss: 1.0268672543\n",
      "Epoch [58000/100000], Train Loss: 0.9894849417, Val Loss: 1.0161835783\n",
      "Epoch [59000/100000], Train Loss: 0.9980810137, Val Loss: 1.0082341075\n",
      "Epoch [60000/100000], Train Loss: 0.9964693008, Val Loss: 1.0023986786\n",
      "Epoch [61000/100000], Train Loss: 0.9965250755, Val Loss: 0.9981908583\n",
      "Epoch [62000/100000], Train Loss: 0.9976304945, Val Loss: 0.9952297870\n",
      "Epoch [63000/100000], Train Loss: 0.9961734547, Val Loss: 0.9932178814\n",
      "Epoch [64000/100000], Train Loss: 0.9968699699, Val Loss: 0.9919231831\n",
      "Epoch [65000/100000], Train Loss: 0.9920939795, Val Loss: 0.9911653908\n",
      "Epoch [66000/100000], Train Loss: 0.9990870085, Val Loss: 0.9908048153\n",
      "Epoch [67000/100000], Train Loss: 0.9986065256, Val Loss: 0.9907336502\n",
      "Epoch [68000/100000], Train Loss: 0.9852675364, Val Loss: 0.9908690770\n",
      "Epoch [69000/100000], Train Loss: 3.6919471400, Val Loss: 0.9911478243\n",
      "Epoch [70000/100000], Train Loss: 0.9991820095, Val Loss: 0.9915218776\n",
      "Epoch [71000/100000], Train Loss: 0.9996442658, Val Loss: 0.9919551007\n",
      "Epoch [72000/100000], Train Loss: 0.9995025053, Val Loss: 0.9924205769\n",
      "Epoch [73000/100000], Train Loss: 0.9969183873, Val Loss: 0.9928985204\n",
      "Epoch [74000/100000], Train Loss: 0.9848726413, Val Loss: 0.9933746379\n",
      "Epoch [75000/100000], Train Loss: 0.9997012897, Val Loss: 0.9938388454\n",
      "Epoch [76000/100000], Train Loss: 0.9983837312, Val Loss: 0.9942842654\n",
      "Epoch [77000/100000], Train Loss: 0.9989357360, Val Loss: 0.9947064452\n",
      "Epoch [78000/100000], Train Loss: 0.9849509070, Val Loss: 0.9951027488\n",
      "Epoch [79000/100000], Train Loss: 0.9978951437, Val Loss: 0.9954718861\n",
      "Epoch [80000/100000], Train Loss: 0.9998210416, Val Loss: 0.9958135489\n",
      "Epoch [81000/100000], Train Loss: 0.9998248536, Val Loss: 0.9961281315\n",
      "Epoch [82000/100000], Train Loss: 0.9996896814, Val Loss: 0.9964165172\n",
      "Epoch [83000/100000], Train Loss: 0.9996557238, Val Loss: 0.9966799157\n",
      "Epoch [84000/100000], Train Loss: 0.9992637664, Val Loss: 0.9969197411\n",
      "Epoch [85000/100000], Train Loss: 0.9993890748, Val Loss: 0.9971375207\n",
      "Epoch [86000/100000], Train Loss: 0.9999288581, Val Loss: 0.9973348281\n",
      "Epoch [87000/100000], Train Loss: 0.9936647669, Val Loss: 0.9975132342\n",
      "Epoch [88000/100000], Train Loss: 0.9997131093, Val Loss: 0.9976742734\n",
      "Epoch [89000/100000], Train Loss: 0.9993196113, Val Loss: 0.9978194197\n",
      "Epoch [90000/100000], Train Loss: 0.9998326931, Val Loss: 0.9979500719\n",
      "Epoch [91000/100000], Train Loss: 0.9995525153, Val Loss: 0.9980675437\n",
      "Epoch [92000/100000], Train Loss: 0.9985939581, Val Loss: 0.9981730598\n",
      "Epoch [93000/100000], Train Loss: 0.9967179097, Val Loss: 0.9982677540\n",
      "Epoch [94000/100000], Train Loss: 0.9701773698, Val Loss: 0.9983526712\n",
      "Epoch [95000/100000], Train Loss: 0.9994732191, Val Loss: 0.9984287692\n",
      "Epoch [96000/100000], Train Loss: 0.9994139110, Val Loss: 0.9984969232\n",
      "Epoch [97000/100000], Train Loss: 0.9999401274, Val Loss: 0.9985579304\n",
      "Epoch [98000/100000], Train Loss: 0.9909207542, Val Loss: 0.9986125148\n",
      "Epoch [99000/100000], Train Loss: 0.9990629886, Val Loss: 0.9986613323\n",
      "Epoch [100000/100000], Train Loss: 0.9991018396, Val Loss: 0.9987049764\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = {\n",
    "            'W1': np.random.uniform(-1, 1, size=(input_size, hidden_size)),\n",
    "            'W2': np.random.uniform(-1, 1, size=(hidden_size, output_size))\n",
    "        }\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights['W1'])\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights['W2'])\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = np.dot(2, self.z2) - y\n",
    "        dLoss_dW2 = np.dot(self.a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.weights['W2'].T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (self.a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "\n",
    "        self.weights['W2'] -= learning_rate * dLoss_dW2 \n",
    "        self.weights['W1'] -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the training data indices\n",
    "            indices = np.random.permutation(len(X_train))\n",
    "\n",
    "            # Perform mini-batch gradient descent\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                # Get the batch indices\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                \n",
    "                # Select the batch data using the shuffled indices\n",
    "                batch_X = X_train[batch_indices]\n",
    "                batch_y = y_train[batch_indices]\n",
    "\n",
    "                # Forward pass and loss calculation for the batch\n",
    "                batch_output = self.forward(batch_X)\n",
    "                batch_loss = np.mean(((batch_output - batch_y)/batch_y) ** 2)\n",
    "                train_loss_history.append(batch_loss)\n",
    "\n",
    "                #print(f'np.max(train_loss_history) = {np.max(train_loss_history)}')\n",
    "\n",
    "                self.backward(batch_X, batch_y, learning_rate)\n",
    "\n",
    "            # Forward pass and loss calculation for validation data\n",
    "            val_output = self.forward(X_val)\n",
    "            val_loss = np.mean((val_output - y_val) ** 2)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {batch_loss:.10f}, Val Loss: {val_loss:.10f}\")\n",
    "\n",
    "        return train_loss_history, val_loss_history\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "g = 9.80665  # Gravitational acceleration\n",
    "\n",
    "# Compute dimensionally homogeneous and normalized inputs/output\n",
    "c4 = training_data['speed']**4\n",
    "training_data['g2h2_c4'] = (g**2 * training_data['height']**2) / c4\n",
    "training_data['g2hl_c4'] = (g**2 * training_data['height'] * training_data['wave_length']) / c4\n",
    "X = training_data[[\"g2h2_c4\", \"g2hl_c4\"]].values\n",
    "y = (c4 / c4).values.reshape(-1, 1)  # Normalized target (always 1)\n",
    "\n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "num_epochs = 100000\n",
    "learning_rate = 0.00000000000001\n",
    "#learning_rate = 0.000000000000000001\n",
    "#learning_rate = 10e-6\n",
    "batch_size = 64\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "train_loss_history, val_loss_history = network.train(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 45384.8641\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c^2=S(gh, g \\sqrt{h\\lambda})$ ---------- $(m^2/s^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000], Train Loss: 1.2853660380, Val Loss: 2.8412032957\n",
      "Epoch [2000/100000], Train Loss: 1.1457251080, Val Loss: 2.5147918769\n",
      "Epoch [3000/100000], Train Loss: 1.1516185122, Val Loss: 2.2691095579\n",
      "Epoch [4000/100000], Train Loss: 1.1802812429, Val Loss: 2.0795121430\n",
      "Epoch [5000/100000], Train Loss: 1.1460239787, Val Loss: 1.9297251073\n",
      "Epoch [6000/100000], Train Loss: 7.8865224527, Val Loss: 1.8093222843\n",
      "Epoch [7000/100000], Train Loss: 1.0311507754, Val Loss: 1.7112009208\n",
      "Epoch [8000/100000], Train Loss: 1.2406377710, Val Loss: 1.6299019296\n",
      "Epoch [9000/100000], Train Loss: 1.0205942237, Val Loss: 1.5616508282\n",
      "Epoch [10000/100000], Train Loss: 1.0589950719, Val Loss: 1.5038043124\n",
      "Epoch [11000/100000], Train Loss: 1.1175093274, Val Loss: 1.4543226820\n",
      "Epoch [12000/100000], Train Loss: 1.0101049121, Val Loss: 1.4116862564\n",
      "Epoch [13000/100000], Train Loss: 1.1519176654, Val Loss: 1.3745497112\n",
      "Epoch [14000/100000], Train Loss: 1.0671953740, Val Loss: 1.3419938176\n",
      "Epoch [15000/100000], Train Loss: 1.2008448867, Val Loss: 1.3133784485\n",
      "Epoch [16000/100000], Train Loss: 1.0759623180, Val Loss: 1.2879966022\n",
      "Epoch [17000/100000], Train Loss: 1.0520176124, Val Loss: 1.2653454438\n",
      "Epoch [18000/100000], Train Loss: 9.4990428591, Val Loss: 1.2450863347\n",
      "Epoch [19000/100000], Train Loss: 1.0280666205, Val Loss: 1.2269536351\n",
      "Epoch [20000/100000], Train Loss: 1.3947713707, Val Loss: 1.2106027435\n",
      "Epoch [21000/100000], Train Loss: 1.0484750031, Val Loss: 1.1957635359\n",
      "Epoch [22000/100000], Train Loss: 1.0618112844, Val Loss: 1.1822980936\n",
      "Epoch [23000/100000], Train Loss: 1.0496937768, Val Loss: 1.1700065297\n",
      "Epoch [24000/100000], Train Loss: 1.0000000000, Val Loss: 1.1587354729\n",
      "Epoch [25000/100000], Train Loss: 1.0000000000, Val Loss: 1.1483791891\n",
      "Epoch [26000/100000], Train Loss: 1.3491226198, Val Loss: 1.1388319457\n",
      "Epoch [27000/100000], Train Loss: 1.2137494987, Val Loss: 1.1300204681\n",
      "Epoch [28000/100000], Train Loss: 1.0025974464, Val Loss: 1.1219386069\n",
      "Epoch [29000/100000], Train Loss: 1.0000000000, Val Loss: 1.1144912239\n",
      "Epoch [30000/100000], Train Loss: 1.0018643454, Val Loss: 1.1076394735\n",
      "Epoch [31000/100000], Train Loss: 1.2267400564, Val Loss: 1.1013292949\n",
      "Epoch [32000/100000], Train Loss: 1.4409669868, Val Loss: 1.0954651519\n",
      "Epoch [33000/100000], Train Loss: 1.0137691917, Val Loss: 1.0900396598\n",
      "Epoch [34000/100000], Train Loss: 1.0399884570, Val Loss: 1.0850067668\n",
      "Epoch [35000/100000], Train Loss: 1.2058492315, Val Loss: 1.0803651726\n",
      "Epoch [36000/100000], Train Loss: 3.5165451625, Val Loss: 1.0760158185\n",
      "Epoch [37000/100000], Train Loss: 1.0000000000, Val Loss: 1.0719229635\n",
      "Epoch [38000/100000], Train Loss: 1.0000000000, Val Loss: 1.0680664387\n",
      "Epoch [39000/100000], Train Loss: 1.0000000000, Val Loss: 1.0644288364\n",
      "Epoch [40000/100000], Train Loss: 1.0041102002, Val Loss: 1.0609963902\n",
      "Epoch [41000/100000], Train Loss: 1.3524344127, Val Loss: 1.0577564777\n",
      "Epoch [42000/100000], Train Loss: 1.0000000000, Val Loss: 1.0546911533\n",
      "Epoch [43000/100000], Train Loss: 1.1476443003, Val Loss: 1.0518215374\n",
      "Epoch [44000/100000], Train Loss: 1.0185874081, Val Loss: 1.0491325183\n",
      "Epoch [45000/100000], Train Loss: 1.0079806863, Val Loss: 1.0465871118\n",
      "Epoch [46000/100000], Train Loss: 1.0000000000, Val Loss: 1.0441992414\n",
      "Epoch [47000/100000], Train Loss: 1.0955243096, Val Loss: 1.0420054143\n",
      "Epoch [48000/100000], Train Loss: 1.1279545857, Val Loss: 1.0399251963\n",
      "Epoch [49000/100000], Train Loss: 2.1997010674, Val Loss: 1.0379459977\n",
      "Epoch [50000/100000], Train Loss: 1.0050259861, Val Loss: 1.0360693713\n",
      "Epoch [51000/100000], Train Loss: 1.0838776519, Val Loss: 1.0342824811\n",
      "Epoch [52000/100000], Train Loss: 1.0000000000, Val Loss: 1.0325777160\n",
      "Epoch [53000/100000], Train Loss: 1.0000000000, Val Loss: 1.0309502786\n",
      "Epoch [54000/100000], Train Loss: 1.0153307715, Val Loss: 1.0293957251\n",
      "Epoch [55000/100000], Train Loss: 1.0000000000, Val Loss: 1.0279153230\n",
      "Epoch [56000/100000], Train Loss: 1.0000000000, Val Loss: 1.0265024432\n",
      "Epoch [57000/100000], Train Loss: 1.8149550264, Val Loss: 1.0251536341\n",
      "Epoch [58000/100000], Train Loss: 1.1553968798, Val Loss: 1.0238667061\n",
      "Epoch [59000/100000], Train Loss: 1.0058103958, Val Loss: 1.0226345030\n",
      "Epoch [60000/100000], Train Loss: 1.0027338949, Val Loss: 1.0214949990\n",
      "Epoch [61000/100000], Train Loss: 1.0000000000, Val Loss: 1.0204233153\n",
      "Epoch [62000/100000], Train Loss: 1.0018797445, Val Loss: 1.0193983588\n",
      "Epoch [63000/100000], Train Loss: 1.0043932669, Val Loss: 1.0184239787\n",
      "Epoch [64000/100000], Train Loss: 1.0000000000, Val Loss: 1.0174906107\n",
      "Epoch [65000/100000], Train Loss: 1.0000000000, Val Loss: 1.0165940261\n",
      "Epoch [66000/100000], Train Loss: 1.0000000000, Val Loss: 1.0157324591\n",
      "Epoch [67000/100000], Train Loss: 1.0025371511, Val Loss: 1.0149053456\n",
      "Epoch [68000/100000], Train Loss: 1.0285199630, Val Loss: 1.0141180995\n",
      "Epoch [69000/100000], Train Loss: 1.0000000000, Val Loss: 1.0133606055\n",
      "Epoch [70000/100000], Train Loss: 1.0369635374, Val Loss: 1.0126315077\n",
      "Epoch [71000/100000], Train Loss: 1.0071227693, Val Loss: 1.0119295250\n",
      "Epoch [72000/100000], Train Loss: 1.0000000000, Val Loss: 1.0112534469\n",
      "Epoch [73000/100000], Train Loss: 1.0000000000, Val Loss: 1.0106059520\n",
      "Epoch [74000/100000], Train Loss: 1.0000000000, Val Loss: 1.0100027003\n",
      "Epoch [75000/100000], Train Loss: 1.0009037260, Val Loss: 1.0094610686\n",
      "Epoch [76000/100000], Train Loss: 1.0000000000, Val Loss: 1.0089619119\n",
      "Epoch [77000/100000], Train Loss: 1.0000000000, Val Loss: 1.0085127042\n",
      "Epoch [78000/100000], Train Loss: 1.0168502455, Val Loss: 1.0080827400\n",
      "Epoch [79000/100000], Train Loss: 1.0000000000, Val Loss: 1.0076741336\n",
      "Epoch [80000/100000], Train Loss: 1.0000000000, Val Loss: 1.0072800151\n",
      "Epoch [81000/100000], Train Loss: 1.0000000000, Val Loss: 1.0068997849\n",
      "Epoch [82000/100000], Train Loss: 1.0000000000, Val Loss: 1.0065362983\n",
      "Epoch [83000/100000], Train Loss: 1.0515402848, Val Loss: 1.0061865977\n",
      "Epoch [84000/100000], Train Loss: 1.0000000000, Val Loss: 1.0058489023\n",
      "Epoch [85000/100000], Train Loss: 1.0000000000, Val Loss: 1.0055227337\n",
      "Epoch [86000/100000], Train Loss: 1.0000000000, Val Loss: 1.0052076353\n",
      "Epoch [87000/100000], Train Loss: 1.0000000000, Val Loss: 1.0049057006\n",
      "Epoch [88000/100000], Train Loss: 1.0000000000, Val Loss: 1.0046163653\n",
      "Epoch [89000/100000], Train Loss: 1.0000000000, Val Loss: 1.0043365841\n",
      "Epoch [90000/100000], Train Loss: 1.0000000000, Val Loss: 1.0041096969\n",
      "Epoch [91000/100000], Train Loss: 1.0000000000, Val Loss: 1.0039022612\n",
      "Epoch [92000/100000], Train Loss: 1.0000000000, Val Loss: 1.0037018230\n",
      "Epoch [93000/100000], Train Loss: 1.0000000000, Val Loss: 1.0035081126\n",
      "Epoch [94000/100000], Train Loss: 1.0080363944, Val Loss: 1.0033208723\n",
      "Epoch [95000/100000], Train Loss: 1.0281748627, Val Loss: 1.0031398555\n",
      "Epoch [96000/100000], Train Loss: 1.0000000000, Val Loss: 1.0029648262\n",
      "Epoch [97000/100000], Train Loss: 1.0000000000, Val Loss: 1.0027955589\n",
      "Epoch [98000/100000], Train Loss: 1.0000000000, Val Loss: 1.0026318374\n",
      "Epoch [99000/100000], Train Loss: 1.0050033436, Val Loss: 1.0024734550\n",
      "Epoch [100000/100000], Train Loss: 1.0000000000, Val Loss: 1.0023202134\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAMWCAYAAAAgRDUeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACaiklEQVR4nOzde3yPdePH8fd3BzuwDWOnNqcbc57DwsgppygR3XWXHIpKoVtyV6hQSrpVbinu7rAkh7uGnyIhGwo5zaGMpNmGzUI2jB2v3x/yvVsbtpnr2uH1fDyux8P38/1c1/X+ruvubm/X9fnaDMMwBAAAAAAAAJjIweoAAAAAAAAAKH8opQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAQJlis9kKtEVFRd3UeSZPniybzVakfaOiooolw82c+/PPPzf93AAAAH/kZHUAAACA4rRt27Zcr1977TVFRkZq48aNucYbNWp0U+cZPny47rrrriLt27JlS23btu2mMwAAAJRmlFIAAKBMadu2ba7X1atXl4ODQ57xP0tLS5O7u3uBzxMYGKjAwMAiZfT09LxhHgAAgLKOx/cAAEC507lzZzVp0kSbN29Wu3bt5O7urscee0yStGzZMvXo0UP+/v5yc3NTw4YN9eKLL+rixYu5jpHf43u1atXSPffco7Vr16ply5Zyc3NTgwYNNH/+/Fzz8nt8b+jQoapUqZJ+/vln9e7dW5UqVVJQUJCee+45paen59r/+PHjuv/+++Xh4aHKlStr4MCB2rlzp2w2m8LDw4vlZ/TDDz+ob9++qlKlilxdXdW8eXN9/PHHuebk5ORo6tSpCg4OlpubmypXrqxmzZrpX//6l33Or7/+qieeeEJBQUFycXFR9erV1b59e23YsKFYcgIAgNKLO6UAAEC5lJiYqEceeUTPP/+83njjDTk4XPm7uiNHjqh3794aM2aMKlasqEOHDmn69OnasWNHnkcA87Nv3z4999xzevHFF+Xr66uPPvpIw4YNU926ddWxY8fr7puZmal7771Xw4YN03PPPafNmzfrtddek5eXl1555RVJ0sWLF9WlSxedPXtW06dPV926dbV27Vo9+OCDN/9D+d3hw4fVrl07+fj4aNasWfL29taiRYs0dOhQnTp1Ss8//7wk6a233tLkyZP10ksvqWPHjsrMzNShQ4d07tw5+7EGDRqkPXv26PXXX1f9+vV17tw57dmzR2fOnCm2vAAAoHSilAIAAOXS2bNn9dlnn+nOO+/MNf7SSy/Z/2wYhtq3b6+GDRuqU6dO2r9/v5o1a3bd454+fVrfffedatSoIUnq2LGjvvnmGy1evPiGpVRGRoamTJmiv/71r5Kkrl27ateuXVq8eLG9lPr444/1888/66uvvrKvadWjRw+lpaXp3//+d+F+CNcwefJkZWRkKDIyUkFBQZKk3r1769y5c5oyZYqefPJJeXl56bvvvlPTpk01efJk+749e/bMdazvvvtOw4cP1+OPP24f69u3b7HkBAAApVu5fnxv8+bN6tOnjwICAmSz2bRy5cpC7X/1tv0/bxUrVrw1gQEAQLGpUqVKnkJKkn755Rc9/PDD8vPzk6Ojo5ydndWpUydJUkxMzA2P27x5c3shJUmurq6qX7++4uLibrivzWZTnz59co01a9Ys176bNm2Sh4dHnkXWH3rooRsev6A2btyorl272gupq4YOHaq0tDT7YvKtW7fWvn379PTTT+vrr79WampqnmO1bt1a4eHhmjp1qrZv367MzMxiywkAAEq3cl1KXbx4USEhIZo9e3aR9h83bpwSExNzbY0aNbL/7SYAACi5/P3984xduHBBHTp00Pfff6+pU6cqKipKO3fu1PLlyyVJly5duuFxvb2984y5uLgUaF93d3e5urrm2ffy5cv212fOnJGvr2+effMbK6ozZ87k+/MJCAiwvy9J48eP14wZM7R9+3b16tVL3t7e9ru7rlq2bJmGDBmijz76SGFhYapataoGDx6spKSkYssLAABKp3JdSvXq1UtTp05V//79830/IyNDzz//vG677TZVrFhRbdq0ybUgaaVKleTn52ffTp06pYMHD2rYsGEmfQIAAFBUf16kXLpyh9DJkyc1f/58DR8+XB07dlRoaKg8PDwsSJg/b29vnTp1Ks94cZY83t7eSkxMzDN+8uRJSVK1atUkSU5OTho7dqz27Nmjs2fPasmSJUpISFDPnj2VlpZmnztz5kwdO3ZMcXFxmjZtmpYvX66hQ4cWW14AAFA6letS6kYeffRRfffdd1q6dKn279+vv/71r7rrrrt05MiRfOd/9NFHql+/vjp06GByUgAAUByuFlUuLi65xotrrabi0KlTJ50/f15fffVVrvGlS5cW2zm6du1qL+j+aOHChXJ3d1fbtm3z7FO5cmXdf//9GjlypM6ePatjx47lmVOjRg2NGjVK3bt31549e4otLwAAKJ1Y6Pwajh49qiVLluj48eP2W9XHjRuntWvXasGCBXrjjTdyzU9PT9enn36qF1980Yq4AACgGLRr105VqlTRiBEjNGnSJDk7O+vTTz/Vvn37rI5mN2TIEL377rt65JFHNHXqVNWtW1dfffWVvv76a0myf4vgjWzfvj3f8U6dOmnSpEn68ssv1aVLF73yyiuqWrWqPv30U61evVpvvfWWvLy8JEl9+vRRkyZNFBoaqurVqysuLk4zZ85UzZo1Va9ePaWkpKhLly56+OGH1aBBA3l4eGjnzp1au3btNe9UBwAA5Qel1DXs2bNHhmGofv36ucbT09PzXSti+fLlOn/+vAYPHmxWRAAAUMy8vb21evVqPffcc3rkkUdUsWJF9e3bV8uWLVPLli2tjidJqlixojZu3KgxY8bo+eefl81mU48ePfTBBx+od+/eqly5coGO8/bbb+c7HhkZqc6dO2vr1q2aMGGCRo4cqUuXLqlhw4ZasGBBrsfuunTpooiICH300UdKTU2Vn5+funfvrpdfflnOzs5ydXVVmzZt9Mknn+jYsWPKzMxUjRo19MILL+j5558vhp8GAAAozWyGYRhWhygJbDabVqxYoX79+km6sijnwIED9eOPP8rR0THX3KtrSf1R165d5enpqRUrVpgVGQAAwO6NN97QSy+9pPj4eAUGBlodBwAA4Ia4U+oaWrRooezsbCUnJ99wjajY2FhFRkZq1apVJqUDAADl2dVvDm7QoIEyMzO1ceNGzZo1S4888giFFAAAKDXKdSl14cIF/fzzz/bXsbGx2rt3r6pWrar69etr4MCBGjx4sN5++221aNFCp0+f1saNG9W0aVP17t3bvt/8+fPl7++vXr16WfExAABAOePu7q53331Xx44dU3p6uv2RuJdeesnqaAAAAAVWrh/fi4qKUpcuXfKMDxkyROHh4crMzNTUqVO1cOFCnThxQt7e3goLC9OUKVPUtGlTSVJOTo5q1qypwYMH6/XXXzf7IwAAAAAAAJRK5bqUAgAAAAAAgDUK9p3BAAAAAAAAQDGilAIAAAAAAIDpyt1C5zk5OTp58qQ8PDxks9msjgMAAAAAAFCmGIah8+fPKyAgQA4O174fqtyVUidPnlRQUJDVMQAAAAAAAMq0hIQEBQYGXvP9cldKeXh4SLryg/H09LQ4DQAAAAAAQNmSmpqqoKAgewdzLeWulLr6yJ6npyelFAAAAAAAwC1yo2WTWOgcAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGC6cremFAAAAAAAuL7s7GxlZmZaHQMllLOzsxwdHW/6OJRSAAAAAABAkmQYhpKSknTu3Dmro6CEq1y5svz8/G64mPn1UEoBAAAAAABJshdSPj4+cnd3v6nCAWWTYRhKS0tTcnKyJMnf37/Ix6KUAgAAAAAAys7OthdS3t7eVsdBCebm5iZJSk5Olo+PT5Ef5WOhcwAAAAAAYF9Dyt3d3eIkKA2uXic3s/YYpRQAAAAAALDjkT0URHFcJ5RSAAAAAAAAMB2lVCl2/Lc0ff1jkgzDsDoKAAAAAABlSufOnTVmzJgCzz927JhsNpv27t17yzKVNZRSpdgd0yP15Ce7teZAktVRAAAAAACwhM1mu+42dOjQIh13+fLleu211wo8PygoSImJiWrSpEmRzldQZan84tv3yoDvY8/o7mZF/wpGAAAAAABKq8TERPufly1bpldeeUWHDx+2j139prirMjMz5ezsfMPjVq1atVA5HB0d5efnV6h9yrsSc6fUtGnTZLPZbnhr3KZNm9SqVSu5urqqTp06mjt3rjkBAQAAAABAiePn52ffvLy8ZLPZ7K8vX76sypUr67///a86d+4sV1dXLVq0SGfOnNFDDz2kwMBAubu7q2nTplqyZEmu4/758b1atWrpjTfe0GOPPSYPDw/VqFFDH374of39P9/BFBUVJZvNpm+++UahoaFyd3dXu3btchVmkjR16lT5+PjIw8NDw4cP14svvqjmzZsX+eeRnp6uZ555Rj4+PnJ1ddUdd9yhnTt32t//7bffNHDgQFWvXl1ubm6qV6+eFixYIEnKyMjQqFGj5O/vL1dXV9WqVUvTpk0rcpYbKRGl1M6dO/Xhhx+qWbNm150XGxur3r17q0OHDoqOjtaECRP0zDPPKCIiwqSkAAAAAACUH4ZhKC0jy5KtONdPfuGFF/TMM88oJiZGPXv21OXLl9WqVSt9+eWX+uGHH/TEE09o0KBB+v777697nLfffluhoaGKjo7W008/raeeekqHDh267j4TJ07U22+/rV27dsnJyUmPPfaY/b1PP/1Ur7/+uqZPn67du3erRo0amjNnzk191ueff14RERH6+OOPtWfPHtWtW1c9e/bU2bNnJUkvv/yyDh48qK+++koxMTGaM2eOqlWrJkmaNWuWVq1apf/+9786fPiwFi1apFq1at1Unuux/PG9CxcuaODAgfrPf/6jqVOnXnfu3LlzVaNGDc2cOVOS1LBhQ+3atUszZszQgAEDTEgLAAAAAED5cSkzW41e+dqScx98tafcKxRPbTFmzBj1798/19i4cePsfx49erTWrl2rzz77TG3atLnmcXr37q2nn35a0pWi691331VUVJQaNGhwzX1ef/11derUSZL04osv6u6779bly5fl6uqq9957T8OGDdOjjz4qSXrllVe0bt06XbhwoUif8+LFi5ozZ47Cw8PVq1cvSdJ//vMfrV+/XvPmzdM//vEPxcfHq0WLFgoNDZWkXKVTfHy86tWrpzvuuEM2m001a9YsUo6CsvxOqZEjR+ruu+9Wt27dbjh327Zt6tGjR66xnj17ateuXcrMzLxVEQEAAAAAQCl2tYC5Kjs7W6+//rqaNWsmb29vVapUSevWrVN8fPx1j/PHJ7yuPiaYnJxc4H38/a+sB311n8OHD6t169a55v/5dWEcPXpUmZmZat++vX3M2dlZrVu3VkxMjCTpqaee0tKlS9W8eXM9//zz2rp1q33u0KFDtXfvXgUHB+uZZ57RunXripylICy9U2rp0qXas2dPrmcbrycpKUm+vr65xnx9fZWVlaXTp0/b/+H+UXp6utLT0+2vU1NTby40AAAAAADlhJuzow6+2tOycxeXihUr5nr99ttv691339XMmTPVtGlTVaxYUWPGjFFGRsZ1j/PnBdJtNptycnIKvI/NZpOkXPtcHbvqZh5bvLpvfse8OtarVy/FxcVp9erV2rBhg7p27aqRI0dqxowZatmypWJjY/XVV19pw4YNeuCBB9StWzd9/vnnRc50PZbdKZWQkKC///3vWrRokVxdXQu837X+Yf15/Kpp06bJy8vLvgUFBRU9NAAAAAAA5YjNZpN7BSdLtmv9nl8ctmzZor59++qRRx5RSEiI6tSpoyNHjtyy811LcHCwduzYkWts165dRT5e3bp1VaFCBX377bf2sczMTO3atUsNGza0j1WvXl1Dhw7VokWLNHPmzFwLtnt6eurBBx/Uf/7zHy1btkwRERH29aiKm2V3Su3evVvJyclq1aqVfSw7O1ubN2/W7NmzlZ6eLkfH3K2on5+fkpKSco0lJyfLyclJ3t7e+Z5n/PjxGjt2rP11amoqxRQAAAAAAOVY3bp1FRERoa1bt6pKlSp65513lJSUlKu4McPo0aP1+OOPKzQ0VO3atdOyZcu0f/9+1alT54b7/vlb/CSpUaNGeuqpp/SPf/xDVatWVY0aNfTWW28pLS1Nw4YNk3Rl3apWrVqpcePGSk9P15dffmn/3O+++678/f3VvHlzOTg46LPPPpOfn58qV65crJ/7KstKqa5du+rAgQO5xh599FE1aNBAL7zwQp5CSpLCwsL0xRdf5Bpbt26dQkND89xCd5WLi4tcXFyKLzgAAAAAACjVXn75ZcXGxqpnz55yd3fXE088oX79+iklJcXUHAMHDtQvv/yicePG6fLly3rggQc0dOjQPHdP5edvf/tbnrHY2Fi9+eabysnJ0aBBg3T+/HmFhobq66+/VpUqVSRJFSpU0Pjx43Xs2DG5ubmpQ4cOWrp0qSSpUqVKmj59uo4cOSJHR0fdfvvtWrNmjRwcbs2DdjajOL9j8SZ17txZzZs3t3+73vjx43XixAktXLhQ0pUfbpMmTfTkk0/q8ccf17Zt2zRixAgtWbKkwN++l5qaKi8vL6WkpMjT0/NWfRRT1HpxtSRpcFhNvdq3icVpAAAAAACl2eXLlxUbG6vatWsXapkdFK/u3bvLz89Pn3zyidVRrut610tBuxdLFzq/kcTExFwr39euXVtr1qzRs88+q/fff18BAQGaNWtWgQspAAAAAACAkiItLU1z585Vz5495ejoqCVLlmjDhg1av3691dFMUaJKqaioqFyvw8PD88zp1KmT9uzZY04gAAAAAACAW8Rms2nNmjWaOnWq0tPTFRwcrIiICHXr1s3qaKYoUaUUAAAAAABAeeHm5qYNGzZYHcMyt2alKpiq5KwKBgAAAAAAUDCUUgAAAAAAADAdpRQAAAAAALDLycmxOgJKgeK4TlhTCgAAAAAAqEKFCnJwcNDJkydVvXp1VahQQTabzepYKGEMw1BGRoZ+/fVXOTg4qEKFCkU+FqUUAAAAAACQg4ODateurcTERJ08edLqOCjh3N3dVaNGDTk4FP0hPEopAAAAAAAg6crdUjVq1FBWVpays7OtjoMSytHRUU5OTjd9Jx2lFAAAAAAAsLPZbHJ2dpazs7PVUVDGsdA5AAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSpUBhgyrIwAAAAAAABQKpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMZ2kpNWfOHDVr1kyenp7y9PRUWFiYvvrqq2vOj4qKks1my7MdOnTIxNQAAAAAAAC4WU5WnjwwMFBvvvmm6tatK0n6+OOP1bdvX0VHR6tx48bX3O/w4cPy9PS0v65evfotzwoAAAAAAIDiY2kp1adPn1yvX3/9dc2ZM0fbt2+/binl4+OjypUr3+J0AAAAAAAAuFVKzJpS2dnZWrp0qS5evKiwsLDrzm3RooX8/f3VtWtXRUZGmpQQAAAAAAAAxcXSO6Uk6cCBAwoLC9Ply5dVqVIlrVixQo0aNcp3rr+/vz788EO1atVK6enp+uSTT9S1a1dFRUWpY8eO+e6Tnp6u9PR0++vU1NRb8jmsZBhWJwAAAAAAACgcy0up4OBg7d27V+fOnVNERISGDBmiTZs25VtMBQcHKzg42P46LCxMCQkJmjFjxjVLqWnTpmnKlCm3LD8AAAAAAAAKz/LH9ypUqKC6desqNDRU06ZNU0hIiP71r38VeP+2bdvqyJEj13x//PjxSklJsW8JCQnFERsAAAAAAAA3wfI7pf7MMIxcj9vdSHR0tPz9/a/5vouLi1xcXIojGgAAAAAAAIqJpaXUhAkT1KtXLwUFBen8+fNaunSpoqKitHbtWklX7nI6ceKEFi5cKEmaOXOmatWqpcaNGysjI0OLFi1SRESEIiIirPwYAAAAAAAAKCRLS6lTp05p0KBBSkxMlJeXl5o1a6a1a9eqe/fukqTExETFx8fb52dkZGjcuHE6ceKE3Nzc1LhxY61evVq9e/e26iMAAAAAAACgCGyGUb6+uy01NVVeXl5KSUmRp6en1XFuSq0XV0uSBrapodfva2pxGgAAAAAAgIJ3L5YvdA4AAAAAAIDyh1IKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUKgMMqwMAAAAAAAAUEqUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpVQYYhtUJAAAAAAAACodSCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOktLqTlz5qhZs2by9PSUp6enwsLC9NVXX113n02bNqlVq1ZydXVVnTp1NHfuXJPSAgAAAAAAoLhYWkoFBgbqzTff1K5du7Rr1y7deeed6tu3r3788cd858fGxqp3797q0KGDoqOjNWHCBD3zzDOKiIgwOTkAAAAAAABuhpOVJ+/Tp0+u16+//rrmzJmj7du3q3Hjxnnmz507VzVq1NDMmTMlSQ0bNtSuXbs0Y8YMDRgwwIzIAAAAAAAAKAYlZk2p7OxsLV26VBcvXlRYWFi+c7Zt26YePXrkGuvZs6d27dqlzMxMM2ICAAAAAACgGFh6p5QkHThwQGFhYbp8+bIqVaqkFStWqFGjRvnOTUpKkq+vb64xX19fZWVl6fTp0/L398+zT3p6utLT0+2vU1NTi/cDAAAAAAAAoNAsv1MqODhYe/fu1fbt2/XUU09pyJAhOnjw4DXn22y2XK8Nw8h3/Kpp06bJy8vLvgUFBRVfeAAAAAAAABSJ5aVUhQoVVLduXYWGhmratGkKCQnRv/71r3zn+vn5KSkpKddYcnKynJyc5O3tne8+48ePV0pKin1LSEgo9s8AAAAAAACAwrH88b0/Mwwj1+N2fxQWFqYvvvgi19i6desUGhoqZ2fnfPdxcXGRi4tLsecEAAAAAABA0Vl6p9SECRO0ZcsWHTt2TAcOHNDEiRMVFRWlgQMHSrpyl9PgwYPt80eMGKG4uDiNHTtWMTExmj9/vubNm6dx48ZZ9REAAAAAAABQBJbeKXXq1CkNGjRIiYmJ8vLyUrNmzbR27Vp1795dkpSYmKj4+Hj7/Nq1a2vNmjV69tln9f777ysgIECzZs3SgAEDrPoIAAAAAAAAKAJLS6l58+Zd9/3w8PA8Y506ddKePXtuUaLSyrA6AAAAAAAAQKFYvtA5AAAAAAAAyh9KKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilygDDsDoBAAAAAABA4VBKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMZ2kpNW3aNN1+++3y8PCQj4+P+vXrp8OHD193n6ioKNlstjzboUOHTEoNAAAAAACAm2VpKbVp0yaNHDlS27dv1/r165WVlaUePXro4sWLN9z38OHDSkxMtG/16tUzITEAAAAAAACKg5OVJ1+7dm2u1wsWLJCPj492796tjh07XndfHx8fVa5c+RamKz0Mw+oEAAAAAAAAhVOi1pRKSUmRJFWtWvWGc1u0aCF/f3917dpVkZGRtzoaAAAAAAAAipGld0r9kWEYGjt2rO644w41adLkmvP8/f314YcfqlWrVkpPT9cnn3yirl27KioqKt+7q9LT05Wenm5/nZqaekvyAwAAAAAAoOBKTCk1atQo7d+/X99+++115wUHBys4ONj+OiwsTAkJCZoxY0a+pdS0adM0ZcqUYs8LAAAAAACAoisRj++NHj1aq1atUmRkpAIDAwu9f9u2bXXkyJF83xs/frxSUlLsW0JCws3GBQAAAAAAwE2y9E4pwzA0evRorVixQlFRUapdu3aRjhMdHS1/f/9833NxcZGLi8vNxAQAAAAAAEAxs7SUGjlypBYvXqz/+7//k4eHh5KSkiRJXl5ecnNzk3TlTqcTJ05o4cKFkqSZM2eqVq1aaty4sTIyMrRo0SJFREQoIiLCss8BAAAAAACAwrG0lJozZ44kqXPnzrnGFyxYoKFDh0qSEhMTFR8fb38vIyND48aN04kTJ+Tm5qbGjRtr9erV6t27t1mxAQAAAAAAcJNshmEYVocwU2pqqry8vJSSkiJPT0+r49yUWi+uliQ9GBqk6fc3szgNAAAAAABAwbuXErHQOQAAAAAAAMoXSikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopcoAQ+VqrXoAAAAAAFAGUEoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTFamUSkhI0PHjx+2vd+zYoTFjxujDDz8stmAAAAAAAAAou4pUSj388MOKjIyUJCUlJal79+7asWOHJkyYoFdffbVYAwIAAAAAAKDsKVIp9cMPP6h169aSpP/+979q0qSJtm7dqsWLFys8PLw48wEAAAAAAKAMKlIplZmZKRcXF0nShg0bdO+990qSGjRooMTExOJLBwAAAAAAgDKpSKVU48aNNXfuXG3ZskXr16/XXXfdJUk6efKkvL29izUgAAAAAAAAyp4ilVLTp0/Xv//9b3Xu3FkPPfSQQkJCJEmrVq2yP9YH8xiG1QkAAAAAAAAKx6koO3Xu3FmnT59WamqqqlSpYh9/4okn5O7uXmzhAAAAAAAAUDYV6U6pS5cuKT093V5IxcXFaebMmTp8+LB8fHyKNSAAAAAAAADKniKVUn379tXChQslSefOnVObNm309ttvq1+/fpozZ06xBgQAAAAAAEDZU6RSas+ePerQoYMk6fPPP5evr6/i4uK0cOFCzZo1q1gDAgAAAAAAoOwpUimVlpYmDw8PSdK6devUv39/OTg4qG3btoqLiyvWgAAAAAAAACh7ilRK1a1bVytXrlRCQoK+/vpr9ejRQ5KUnJwsT0/PAh9n2rRpuv322+Xh4SEfHx/169dPhw8fvuF+mzZtUqtWreTq6qo6depo7ty5RfkYAAAAAAAAsEiRSqlXXnlF48aNU61atdS6dWuFhYVJunLXVIsWLQp8nE2bNmnkyJHavn271q9fr6ysLPXo0UMXL1685j6xsbHq3bu3OnTooOjoaE2YMEHPPPOMIiIiivJRAAAAAAAAYAGbYRhGUXZMSkpSYmKiQkJC5OBwpdvasWOHPD091aBBgyKF+fXXX+Xj46NNmzapY8eO+c554YUXtGrVKsXExNjHRowYoX379mnbtm03PEdqaqq8vLyUkpJSqLu6SqJaL66WJP21VaD++dcQi9MAAAAAAAAUvHtxKuoJ/Pz85Ofnp+PHj8tms+m2225T69ati3o4SVJKSookqWrVqtecs23bNvvjglf17NlT8+bNU2ZmppydnXO9l56ervT0dPvr1NTUm8oIAAAAAACAm1ekx/dycnL06quvysvLSzVr1lSNGjVUuXJlvfbaa8rJySlSEMMwNHbsWN1xxx1q0qTJNeclJSXJ19c315ivr6+ysrJ0+vTpPPOnTZsmLy8v+xYUFFSkfAAAAAAAACg+RbpTauLEiZo3b57efPNNtW/fXoZh6LvvvtPkyZN1+fJlvf7664U+5qhRo7R//359++23N5xrs9lyvb76BOKfxyVp/PjxGjt2rP11amoqxRQAAAAAAIDFilRKffzxx/roo49077332sdCQkJ022236emnny50KTV69GitWrVKmzdvVmBg4HXn+vn5KSkpKddYcnKynJyc5O3tnWe+i4uLXFxcCpUHAAAAAAAAt1aRHt87e/ZsvouZN2jQQGfPni3wcQzD0KhRo7R8+XJt3LhRtWvXvuE+YWFhWr9+fa6xdevWKTQ0NM96UgAAAAAAACiZilRKhYSEaPbs2XnGZ8+erWbNmhX4OCNHjtSiRYu0ePFieXh4KCkpSUlJSbp06ZJ9zvjx4zV48GD76xEjRiguLk5jx45VTEyM5s+fr3nz5mncuHFF+ShlQpG+PhEAAAAAAMBCRXp876233tLdd9+tDRs2KCwsTDabTVu3blVCQoLWrFlT4OPMmTNHktS5c+dc4wsWLNDQoUMlSYmJiYqPj7e/V7t2ba1Zs0bPPvus3n//fQUEBGjWrFkaMGBAUT4KAAAAAAAALFCkUqpTp0766aef9P777+vQoUMyDEP9+/fXE088ocmTJ6tDhw4FOs7VBcqvJzw8PN/z79mzp7CxAQAAAAAAUEIUqZSSpICAgDwLmu/bt08ff/yx5s+ff9PBAAAAAAAAUHYVaU0pAAAAAAAA4GZQSgEAAAAAAMB0lFIAAAAAAAAwXaHWlOrfv/913z937tzNZAEAAAAAAEA5UahSysvL64bvDx48+KYCAQAAAAAAoOwrVCm1YMGCW5UDAAAAAAAA5QhrSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpVQYYhtUJAAAAAAAACodSCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKaztJTavHmz+vTpo4CAANlsNq1cufK686OiomSz2fJshw4dMidwCWXIsDoCAAAAAABAoThZefKLFy8qJCREjz76qAYMGFDg/Q4fPixPT0/76+rVq9+KeAAAAAAAALhFLC2levXqpV69ehV6Px8fH1WuXLn4AwEAAAAAAMAUpXJNqRYtWsjf319du3ZVZGTkdeemp6crNTU11wYAAAAAAABrlapSyt/fXx9++KEiIiK0fPlyBQcHq2vXrtq8efM195k2bZq8vLzsW1BQkImJAQAAAAAAkB9LH98rrODgYAUHB9tfh4WFKSEhQTNmzFDHjh3z3Wf8+PEaO3as/XVqairFFAAAAAAAgMVK1Z1S+Wnbtq2OHDlyzfddXFzk6emZawMAAAAAAIC1Sn0pFR0dLX9/f6tjAAAAAAAAoBAsfXzvwoUL+vnnn+2vY2NjtXfvXlWtWlU1atTQ+PHjdeLECS1cuFCSNHPmTNWqVUuNGzdWRkaGFi1apIiICEVERFj1EQAAAAAAAFAElpZSu3btUpcuXeyvr679NGTIEIWHhysxMVHx8fH29zMyMjRu3DidOHFCbm5uaty4sVavXq3evXubnh0AAAAAAABFZzMMw7A6hJlSU1Pl5eWllJSUUr++VK0XV0uS+re8Te880NzaMAAAAAAAACp491Lq15QCAAAAAABA6UMpBQAAAAAAANNRSpUF5eoBTAAAAAAAUBZQSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFJlgGF1AAAAAAAAgEKilAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmM7SUmrz5s3q06ePAgICZLPZtHLlyhvus2nTJrVq1Uqurq6qU6eO5s6de+uDAgAAAAAAoFhZWkpdvHhRISEhmj17doHmx8bGqnfv3urQoYOio6M1YcIEPfPMM4qIiLjFSQEAAAAAAFCcnKw8ea9evdSrV68Cz587d65q1KihmTNnSpIaNmyoXbt2acaMGRowYMAtSgkAAAAAAIDiVqrWlNq2bZt69OiRa6xnz57atWuXMjMz890nPT1dqampuTYAAAAAAABYq1SVUklJSfL19c015uvrq6ysLJ0+fTrffaZNmyYvLy/7FhQUZEZUAAAAAAAAXEepKqUkyWaz5XptGEa+41eNHz9eKSkp9i0hIeGWZwQAAAAAAMD1WbqmVGH5+fkpKSkp11hycrKcnJzk7e2d7z4uLi5ycXExI55lrhZzAAAAAAAApUWpulMqLCxM69evzzW2bt06hYaGytnZ2aJUAAAAAAAAKCxLS6kLFy5o79692rt3ryQpNjZWe/fuVXx8vKQrj94NHjzYPn/EiBGKi4vT2LFjFRMTo/nz52vevHkaN26cFfEBAAAAAABQRJY+vrdr1y516dLF/nrs2LGSpCFDhig8PFyJiYn2gkqSateurTVr1ujZZ5/V+++/r4CAAM2aNUsDBgwwPTsAAAAAAACKztJSqnPnztddDyk8PDzPWKdOnbRnz55bmAoAAAAAAAC3WqlaUwoAAAAAAABlA6UUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFJlgGF1AAAAAAAAgEKilAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKXKAMOwOgEAAAAAAEDhUEoBAAAAAADAdJaXUh988IFq164tV1dXtWrVSlu2bLnm3KioKNlstjzboUOHTEwMAAAAAACAm2VpKbVs2TKNGTNGEydOVHR0tDp06KBevXopPj7+uvsdPnxYiYmJ9q1evXomJQYAAAAAAEBxsLSUeueddzRs2DANHz5cDRs21MyZMxUUFKQ5c+Zcdz8fHx/5+fnZN0dHR5MSAwAAAAAAoDhYVkplZGRo9+7d6tGjR67xHj16aOvWrdfdt0WLFvL391fXrl0VGRl53bnp6elKTU3NtQEAAAAAAMBalpVSp0+fVnZ2tnx9fXON+/r6KikpKd99/P399eGHHyoiIkLLly9XcHCwunbtqs2bN1/zPNOmTZOXl5d9CwoKKtbPAQAAAAAAgMJzsjqAzWbL9dowjDxjVwUHBys4ONj+OiwsTAkJCZoxY4Y6duyY7z7jx4/X2LFj7a9TU1MppgAAAAAAACxm2Z1S1apVk6OjY567opKTk/PcPXU9bdu21ZEjR675vouLizw9PXNtAAAAAAAAsJZlpVSFChXUqlUrrV+/Ptf4+vXr1a5duwIfJzo6Wv7+/sUdDwAAAAAAALeQpY/vjR07VoMGDVJoaKjCwsL04YcfKj4+XiNGjJB05dG7EydOaOHChZKkmTNnqlatWmrcuLEyMjK0aNEiRUREKCIiwsqPAQAAAAAAgEKytJR68MEHdebMGb366qtKTExUkyZNtGbNGtWsWVOSlJiYqPj4ePv8jIwMjRs3TidOnJCbm5saN26s1atXq3fv3lZ9BAAAAAAAABSBzTAMw+oQZkpNTZWXl5dSUlJK/fpStV5cLUm6NyRAsx5qYXEaAAAAAACAgncvlq0pheJTrlpFAAAAAABQJlBKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUmWAYRhWRwAAAAAAACgUSikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6y0upDz74QLVr15arq6tatWqlLVu2XHf+pk2b1KpVK7m6uqpOnTqaO3euSUkBAAAAAABQXCwtpZYtW6YxY8Zo4sSJio6OVocOHdSrVy/Fx8fnOz82Nla9e/dWhw4dFB0drQkTJuiZZ55RRESEyckBAAAAAABwMywtpd555x0NGzZMw4cPV8OGDTVz5kwFBQVpzpw5+c6fO3euatSooZkzZ6phw4YaPny4HnvsMc2YMcPk5AAAAAAAALgZTladOCMjQ7t379aLL76Ya7xHjx7aunVrvvts27ZNPXr0yDXWs2dPzZs3T5mZmXJ2dr5leUuyMxcydPpCutUxAAAAAADATfJyc5azo+WrLZnCslLq9OnTys7Olq+vb65xX19fJSUl5btPUlJSvvOzsrJ0+vRp+fv759knPT1d6en/K2xSU1OLIX3Jsu2XMwqdusHqGAAAAAAA4CZ9OfoONbnNy+oYprC8erPZbLleG4aRZ+xG8/Mbv2ratGny8vKyb0FBQTeZGAAAAAAAADfLsjulqlWrJkdHxzx3RSUnJ+e5G+oqPz+/fOc7OTnJ29s7333Gjx+vsWPH2l+npqaWmWLq2Jt3Wx0BAAAAAACgSCy7U6pChQpq1aqV1q9fn2t8/fr1ateuXb77hIWF5Zm/bt06hYaGXnM9KRcXF3l6eubaAAAAAAAAYC1LH98bO3asPvroI82fP18xMTF69tlnFR8frxEjRki6cpfT4MGD7fNHjBihuLg4jR07VjExMZo/f77mzZuncePGWfURAAAAAAAAUASWPb4nSQ8++KDOnDmjV199VYmJiWrSpInWrFmjmjVrSpISExMVHx9vn1+7dm2tWbNGzz77rN5//30FBARo1qxZGjBggFUfAQAAAAAAAEVgM66uFF5OpKamysvLSykpKTzKBwAAAAAAUMwK2r1Y/u17AAAAAAAAKH8opQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYzsnqAGYzDEOSlJqaanESAAAAAACAsudq53K1g7mWcldKnT9/XpIUFBRkcRIAAAAAAICy6/z58/Ly8rrm+zbjRrVVGZOTk6OTJ0/Kw8NDNpvN6jg3JTU1VUFBQUpISJCnp6fVcVAOcM3BTFxvMBvXHMzE9QYzcb3BbFxzMAxD58+fV0BAgBwcrr1yVLm7U8rBwUGBgYFWxyhWnp6e/A8dpuKag5m43mA2rjmYiesNZuJ6g9m45sq3690hdRULnQMAAAAAAMB0lFIAAAAAAAAwHaVUKebi4qJJkybJxcXF6igoJ7jmYCauN5iNaw5m4nqDmbjeYDauORRUuVvoHAAAAAAAANbjTikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SqkS7oMPPlDt2rXl6uqqVq1aacuWLdedv2nTJrVq1Uqurq6qU6eO5s6da1JSlBWFueaWL1+u7t27q3r16vL09FRYWJi+/vprE9OitCvsv+Ou+u677+Tk5KTmzZvf2oAoUwp7vaWnp2vixImqWbOmXFxc9Je//EXz5883KS3KgsJec59++qlCQkLk7u4uf39/Pfroozpz5oxJaVGabd68WX369FFAQIBsNptWrlx5w334vQFFVdjrjd8ZcD2UUiXYsmXLNGbMGE2cOFHR0dHq0KGDevXqpfj4+Hznx8bGqnfv3urQoYOio6M1YcIEPfPMM4qIiDA5OUqrwl5zmzdvVvfu3bVmzRrt3r1bXbp0UZ8+fRQdHW1ycpRGhb3erkpJSdHgwYPVtWtXk5KiLCjK9fbAAw/om2++0bx583T48GEtWbJEDRo0MDE1SrPCXnPffvutBg8erGHDhunHH3/UZ599pp07d2r48OEmJ0dpdPHiRYWEhGj27NkFms/vDbgZhb3e+J0B12MzDMOwOgTy16ZNG7Vs2VJz5syxjzVs2FD9+vXTtGnT8sx/4YUXtGrVKsXExNjHRowYoX379mnbtm2mZEbpVthrLj+NGzfWgw8+qFdeeeVWxUQZUdTr7W9/+5vq1asnR0dHrVy5Unv37jUhLUq7wl5va9eu1d/+9jf98ssvqlq1qplRUUYU9pqbMWOG5syZo6NHj9rH3nvvPb311ltKSEgwJTPKBpvNphUrVqhfv37XnMPvDSguBbne8sPvDLiKO6VKqIyMDO3evVs9evTINd6jRw9t3bo13322bduWZ37Pnj21a9cuZWZm3rKsKBuKcs39WU5Ojs6fP88vcLihol5vCxYs0NGjRzVp0qRbHRFlSFGut1WrVik0NFRvvfWWbrvtNtWvX1/jxo3TpUuXzIiMUq4o11y7du10/PhxrVmzRoZh6NSpU/r888919913mxEZ5Qy/N8BK/M6AP3KyOgDyd/r0aWVnZ8vX1zfXuK+vr5KSkvLdJykpKd/5WVlZOn36tPz9/W9ZXpR+Rbnm/uztt9/WxYsX9cADD9yKiChDinK9HTlyRC+++KK2bNkiJyf+7wsFV5Tr7ZdfftG3334rV1dXrVixQqdPn9bTTz+ts2fPsq4Ubqgo11y7du306aef6sEHH9Tly5eVlZWle++9V++9954ZkVHO8HsDrMTvDPgj7pQq4Ww2W67XhmHkGbvR/PzGgWsp7DV31ZIlSzR58mQtW7ZMPj4+tyoeypiCXm/Z2dl6+OGHNWXKFNWvX9+seChjCvPvt5ycHNlsNn366adq3bq1evfurXfeeUfh4eHcLYUCK8w1d/DgQT3zzDN65ZVXtHv3bq1du1axsbEaMWKEGVFRDvF7A6zA7wz4M/6quYSqVq2aHB0d8/xtWnJycp6/1bjKz88v3/lOTk7y9va+ZVlRNhTlmrtq2bJlGjZsmD777DN169btVsZEGVHY6+38+fPatWuXoqOjNWrUKElXSgPDMOTk5KR169bpzjvvNCU7Sp+i/PvN399ft912m7y8vOxjDRs2lGEYOn78uOrVq3dLM6N0K8o1N23aNLVv317/+Mc/JEnNmjVTxYoV1aFDB02dOpU7V1Cs+L0BVuB3BuSHO6VKqAoVKqhVq1Zav359rvH169erXbt2+e4TFhaWZ/66desUGhoqZ2fnW5YVZUNRrjnpyt92DB06VIsXL2bdCxRYYa83T09PHThwQHv37rVvI0aMUHBwsPbu3as2bdqYFR2lUFH+/da+fXudPHlSFy5csI/99NNPcnBwUGBg4C3Ni9KvKNdcWlqaHBxy/6e5o6OjpP/dwQIUF35vgNn4nQHXZKDEWrp0qeHs7GzMmzfPOHjwoDFmzBijYsWKxrFjxwzDMIwXX3zRGDRokH3+L7/8Yri7uxvPPvuscfDgQWPevHmGs7Oz8fnnn1v1EVDKFPaaW7x4seHk5GS8//77RmJion07d+6cVR8BpUhhr7c/mzRpkhESEmJSWpR2hb3ezp8/bwQGBhr333+/8eOPPxqbNm0y6tWrZwwfPtyqj4BSprDX3IIFCwwnJyfjgw8+MI4ePWp8++23RmhoqNG6dWurPgJKkfPnzxvR0dFGdHS0Icl45513jOjoaCMuLs4wDH5vQPEq7PXG7wy4HkqpEu799983atasaVSoUMFo2bKlsWnTJvt7Q4YMMTp16pRrflRUlNGiRQujQoUKRq1atYw5c+aYnBilXWGuuU6dOhmS8mxDhgwxPzhKpcL+O+6PKKVQWIW93mJiYoxu3boZbm5uRmBgoDF27FgjLS3N5NQozQp7zc2aNcto1KiR4ebmZvj7+xsDBw40jh8/bnJqlEaRkZHX/W8yfm9AcSrs9cbvDLgem2FwPzAAAAAAAADMxZpSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAACUUTabTStXrrQ6BgAAKGE2b96sPn36KCAgoMj/vWAYhmbMmKH69evLxcVFQUFBeuONNwp1DEopAACAW2Do0KGy2Wx5trvuusvqaAAAoJy7ePGiQkJCNHv27CIf4+9//7s++ugjzZgxQ4cOHdIXX3yh1q1bF+oYTkU+OwAAAK7rrrvu0oIFC3KNubi4WJQGAADgil69eqlXr17XfD8jI0MvvfSSPv30U507d05NmjTR9OnT1blzZ0lSTEyM5syZox9++EHBwcFFzsGdUgAAALeIi4uL/Pz8cm1VqlSRdOXRujlz5qhXr15yc3NT7dq19dlnn+Xa/8CBA7rzzjvl5uYmb29vPfHEE7pw4UKuOfPnz1fjxo3l4uIif39/jRo1Ktf7p0+f1n333Sd3d3fVq1dPq1aturUfGgAAlHqPPvqovvvuOy1dulT79+/XX//6V9111106cuSIJOmLL75QnTp19OWXX6p27dqqVauWhg8frrNnzxbqPJRSAAAAFnn55Zc1YMAA7du3T4888ogeeughxcTESJLS0tJ01113qUqVKtq5c6c+++wzbdiwIVfpNGfOHI0cOVJPPPGEDhw4oFWrVqlu3bq5zjFlyhQ98MAD2r9/v3r37q2BAwcW+j8YAQBA+XH06FEtWbJEn332mTp06KC//OUvGjdunO644w77HeC//PKL4uLi9Nlnn2nhwoUKDw/X7t27df/99xfqXDy+BwAAcIt8+eWXqlSpUq6xF154QS+//LIk6a9//auGDx8uSXrttde0fv16vffee/rggw/06aef6tKlS1q4cKEqVqwoSZo9e7b69Omj6dOny9fXV1OnTtVzzz2nv//97/bj33777bnON3ToUD300EOSpDfeeEPvvfeeduzYwdpWAAAgX3v27JFhGKpfv36u8fT0dHl7e0uScnJylJ6eroULF9rnzZs3T61atdLhw4cL/EgfpRQAAMAt0qVLF82ZMyfXWNWqVe1/DgsLy/VeWFiY9u7dK+nKWg0hISH2QkqS2rdvr5ycHB0+fFg2m00nT55U165dr5uhWbNm9j9XrFhRHh4eSk5OLupHAgAAZVxOTo4cHR21e/duOTo65nrv6l+2+fv7y8nJKVdx1bBhQ0lSfHw8pRQAAIDVKlasmOdxuhux2WySrnzN8tU/5zfHzc2tQMdzdnbOs29OTk6hMgEAgPKjRYsWys7OVnJysjp06JDvnPbt2ysrK0tHjx7VX/7yF0nSTz/9JEmqWbNmgc/FmlIAAAAW2b59e57XDRo0kCQ1atRIe/fu1cWLF+3vf/fdd3JwcFD9+vXl4eGhWrVq6ZtvvjE1MwAAKP0uXLigvXv32u/Qjo2N1d69exUfH6/69etr4MCBGjx4sJYvX67Y2Fjt3LlT06dP15o1ayRJ3bp1U8uWLfXYY48pOjpau3fv1pNPPqnu3bvneezveiilAAAAbpH09HQlJSXl2k6fPm1//7PPPtP8+fP1008/adKkSdqxY4d9IfOBAwfK1dVVQ4YM0Q8//KDIyEiNHj1agwYNkq+vryRp8uTJevvttzVr1iwdOXJEe/bs0XvvvWfJZwUAAKXHrl271KJFC7Vo0UKSNHbsWLVo0UKvvPKKJGnBggUaPHiwnnvuOQUHB+vee+/V999/r6CgIEmSg4ODvvjiC1WrVk0dO3bU3XffrYYNG2rp0qWFysHjewAAALfI2rVr5e/vn2ssODhYhw4dknTlm/GWLl2qp59+Wn5+fvr000/VqFEjSZK7u7u+/vpr/f3vf9ftt98ud3d3DRgwQO+88479WEOGDNHly5f17rvvaty4capWrVqhv/UGAACUP507d5ZhGNd839nZWVOmTNGUKVOuOScgIEARERE3lcNmXC8FAAAAbgmbzaYVK1aoX79+VkcBAACwBI/vAQAAAAAAwHSUUgAAAAAAADAda0oBAABYgBUUAABAecedUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAABKjfvuu09ubm46d+7cNecMHDhQzs7OOnXqVIGPa7PZNHnyZPvrqKgo2Ww2RUVF3XDfoUOHqlatWgU+1x998MEHCg8PzzN+7Ngx2Wy2fN+71SZPniybzabTp0+bfm4AAFC+UEoBAIBSY9iwYbp8+bIWL16c7/spKSlasWKF7rnnHvn6+hb5PC1bttS2bdvUsmXLIh+jIK5VSvn7+2vbtm26++67b+n5AQAArEQpBQAASo1evXopICBA8+fPz/f9JUuW6NKlSxo2bNhNncfT01Nt27aVp6fnTR2nqFxcXNS2bVtVr17dkvMDAACYgVIKAACUGo6OjhoyZIh2796tAwcO5Hl/wYIF8vf3V69evfTrr7/q6aefVqNGjVSpUiX5+Pjozjvv1JYtW254nms9vhceHq7g4GC5uLioYcOGWrhwYb77T5kyRW3atFHVqlXl6empli1bat68eTIMwz6nVq1a+vHHH7Vp0ybZbDbZbDb7Y4DXenzv22+/VdeuXeXh4SF3d3e1a9dOq1evzpPRZrMpMjJSTz31lKpVqyZvb2/1799fJ0+evOFnL6hVq1YpLCxM7u7u8vDwUPfu3bVt27Zcc3799Vc98cQTCgoKkouLi6pXr6727dtrw4YN9jnR0dG655575OPjIxcXFwUEBOjuu+/W8ePHiy0rAAAomSilAABAqfLYY4/JZrPluVvq4MGD2rFjh4YMGSJHR0edPXtWkjRp0iStXr1aCxYsUJ06ddS5c+cCrRX1Z+Hh4Xr00UfVsGFDRURE6KWXXtJrr72mjRs35pl77NgxPfnkk/rvf/+r5cuXq3///ho9erRee+01+5wVK1aoTp06atGihbZt26Zt27ZpxYoV1zz/pk2bdOeddyolJUXz5s3TkiVL5OHhoT59+mjZsmV55g8fPlzOzs5avHix3nrrLUVFRemRRx4p9OfOz+LFi9W3b195enpqyZIlmjdvnn777Td17txZ3377rX3eoEGDtHLlSr3yyitat26dPvroI3Xr1k1nzpyRJF28eFHdu3fXqVOn9P7772v9+vWaOXOmatSoofPnzxdLVgAAUIIZAAAApUynTp2MatWqGRkZGfax5557zpBk/PTTT/nuk5WVZWRmZhpdu3Y17rvvvlzvSTImTZpkfx0ZGWlIMiIjIw3DMIzs7GwjICDAaNmypZGTk2Ofd+zYMcPZ2dmoWbPmNbNmZ2cbmZmZxquvvmp4e3vn2r9x48ZGp06d8uwTGxtrSDIWLFhgH2vbtq3h4+NjnD9/PtdnatKkiREYGGg/7oIFCwxJxtNPP53rmG+99ZYhyUhMTLxmVsMwjEmTJhmSjF9//fWanycgIMBo2rSpkZ2dbR8/f/684ePjY7Rr184+VqlSJWPMmDHXPNeuXbsMScbKlSuvmwkAAJRN3CkFAABKnWHDhun06dNatWqVJCkrK0uLFi1Shw4dVK9ePfu8uXPnqmXLlnJ1dZWTk5OcnZ31zTffKCYmplDnO3z4sE6ePKmHH35YNpvNPl6zZk21a9cuz/yNGzeqW7du8vLykqOjo5ydnfXKK6/ozJkzSk5OLvTnvXjxor7//nvdf//9qlSpkn3c0dFRgwYN0vHjx3X48OFc+9x77725Xjdr1kySFBcXV+jz/9HVn8WgQYPk4PC//5SsVKmSBgwYoO3btystLU2S1Lp1a4WHh2vq1Knavn27MjMzcx2rbt26qlKlil544QXNnTtXBw8evKlsAACgdKGUAgAApc79998vLy8vLViwQJK0Zs0anTp1KtcC5++8846eeuoptWnTRhEREdq+fbt27typu+66S5cuXSrU+a4+bubn55fnvT+P7dixQz169JAk/ec//9F3332nnTt3auLEiZJU6HNL0m+//SbDMOTv75/nvYCAgFwZr/L29s712sXFpcjn/6Or57lWlpycHP3222+SpGXLlmnIkCH66KOPFBYWpqpVq2rw4MFKSkqSJHl5eWnTpk1q3ry5JkyYoMaNGysgIECTJk3KU2ABAICyx8nqAAAAAIXl5uamhx56SP/5z3+UmJio+fPny8PDQ3/961/tcxYtWqTOnTtrzpw5ufYtylpFVwueq2XKH/15bOnSpXJ2dtaXX34pV1dX+/jKlSsLfd6rqlSpIgcHByUmJuZ57+ri5dWqVSvy8Qvj6s/iWlkcHBxUpUoVe6aZM2dq5syZio+P16pVq/Tiiy8qOTlZa9eulSQ1bdpUS5culWEY2r9/v8LDw/Xqq6/Kzc1NL774oimfCQAAWIM7pQAAQKk0bNgwZWdn65///KfWrFmjv/3tb3J3d7e/b7PZ7HcHXbV///483xBXEMHBwfL399eSJUtyfYNeXFyctm7dmmuuzWaTk5OTHB0d7WOXLl3SJ598kue4Li4uBbpzqWLFimrTpo2WL1+ea35OTo4WLVqkwMBA1a9fv9CfqyiCg4N12223afHixbl+FhcvXlRERIT9G/n+rEaNGho1apS6d++uPXv25HnfZrMpJCRE7777ripXrpzvHAAAULZwpxQAACiVQkND1axZM82cOVOGYeR6dE+S7rnnHr322muaNGmSOnXqpMOHD+vVV19V7dq1lZWVVahzOTg46LXXXtPw4cN133336fHHH9e5c+c0efLkPI/v3X333XrnnXf08MMP64knntCZM2c0Y8aMPAWZ9L+7hJYtW6Y6derI1dVVTZs2zTfDtGnT1L17d3Xp0kXjxo1ThQoV9MEHH+iHH37QkiVLcq11VRy++OILeXh45Bm///779dZbb2ngwIG655579OSTTyo9PV3//Oc/de7cOb355puSpJSUFHXp0kUPP/ywGjRoIA8PD+3cuVNr165V//79JUlffvmlPvjgA/Xr10916tSRYRhavny5zp07p+7duxfr5wEAACUPpRQAACi1hg0bpr///e9q1KiR2rRpk+u9iRMnKi0tTfPmzdNbb72lRo0aae7cuVqxYoWioqKKdC5Jmj59uvr3769atWppwoQJ2rRpU67j3XnnnZo/f76mT5+uPn366LbbbtPjjz8uHx+fPMXZlClTlJiYqMcff1znz59XzZo1dezYsXzP36lTJ23cuFGTJk3S0KFDlZOTo5CQEK1atUr33HNPoT/PjTz22GP5jhuGoYcfflgVK1bUtGnT9OCDD8rR0VFt27ZVZGSkfeF3V1dXtWnTRp988omOHTumzMxM1ahRQy+88IKef/55SVK9evVUuXJlvfXWWzp58qQqVKig4OBghYeHa8iQIcX+mQAAQMliM/543zUAAAAAAABgAtaUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYzsnqAGbLycnRyZMn5eHhIZvNZnUcAAAAAACAMsUwDJ0/f14BAQFycLj2/VDlrpQ6efKkgoKCrI4BAAAAAABQpiUkJCgwMPCa75e7UsrDw0PSlR+Mp6enxWkAAAAAAADKltTUVAUFBdk7mGspd6XU1Uf2PD09KaUAAAAAAABukRstm8RC5wAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA05W7NaUAAAAAACgvcnJylJGRYXUMlDHOzs5ydHS86eNQSgEAAAAAUAZlZGQoNjZWOTk5VkdBGVS5cmX5+fndcDHz66GUAgAAAACgjDEMQ4mJiXJ0dFRQUJAcHFi9B8XDMAylpaUpOTlZkuTv71/kY1FKAQAAAABQxmRlZSktLU0BAQFyd3e3Og7KGDc3N0lScnKyfHx8ivwoH1UpAAAAAABlTHZ2tiSpQoUKFidBWXW17MzMzCzyMSilAAAAAAAoo25mvR/georj2qKUKuUys3OUnWNYHQMAAAAAgBKhc+fOGjNmjP11rVq1NHPmzOvuY7PZtHLlyps+d3Edp7yglCrFHvz3NjV8ea1+PJlidRQAAAAAAG5Knz591K1bt3zf27Ztm2w2m/bs2VPo4+7cuVNPPPHEzcbLZfLkyWrevHme8cTERPXq1atYz/Vn4eHhqly58i09h1kopUoxm03KyjF05NQFq6MAAAAAAHBThg0bpo0bNyouLi7Pe/Pnz1fz5s3VsmXLQh+3evXqpi327ufnJxcXF1POVRZQSpVidX0qSZJ+/pVSCgAAAABQut1zzz3y8fFReHh4rvG0tDQtW7ZMw4YN05kzZ/TQQw8pMDBQ7u7uatq0qZYsWXLd4/758b0jR46oY8eOcnV1VaNGjbR+/fo8+7zwwguqX7++3N3dVadOHb388sv2Bb3Dw8M1ZcoU7du3TzabTTabzZ75z4/vHThwQHfeeafc3Nzk7e2tJ554Qhcu/O93+KFDh6pfv36aMWOG/P395e3trZEjR97U4uHx8fHq27evKlWqJE9PTz3wwAM6deqU/f19+/apS5cu8vDwkKenp1q1aqVdu3ZJkuLi4tSnTx9VqVJFFStWVOPGjbVmzZoiZ7kRp1t2ZNxy9Xw8JEk/J1NKAQAAAACuzTAMXcrMtuTcbs6OBVoU28nJSYMHD1Z4eLheeeUV+z6fffaZMjIyNHDgQKWlpalVq1Z64YUX5OnpqdWrV2vQoEGqU6eO2rRpc8Nz5OTkqH///qpWrZq2b9+u1NTUXOtPXeXh4aHw8HAFBATowIEDevzxx+Xh4aHnn39eDz74oH744QetXbtWGzZskCR5eXnlOUZaWpruuusutW3bVjt37lRycrKGDx+uUaNG5SreIiMj5e/vr8jISP3888968MEH1bx5cz3++OM3/Dx/ZhiG+vXrp4oVK2rTpk3KysrS008/rQcffFBRUVGSpIEDB6pFixaaM2eOHB0dtXfvXjk7O0uSRo4cqYyMDG3evFkVK1bUwYMHValSpULnKChKqVLMfqcUpRQAAAAA4DouZWar0StfW3Lug6/2lHuFgtUPjz32mP75z38qKipKXbp0kXTl0b3+/furSpUqqlKlisaNG2efP3r0aK1du1afffZZgUqpDRs2KCYmRseOHVNgYKAk6Y033sizDtRLL71k/3OtWrX03HPPadmyZXr++efl5uamSpUqycnJSX5+ftc816effqpLly5p4cKFqlixoiRp9uzZ6tOnj6ZPny5fX19JUpUqVTR79mw5OjqqQYMGuvvuu/XNN98UqZTasGGD9u/fr9jYWAUFBUmSPvnkEzVu3Fg7d+7U7bffrvj4eP3jH/9QgwYNJEn16tWz7x8fH68BAwaoadOmkqQ6deoUOkNh8PheKXa1lIo7c1HpWdY03gAAAAAAFJcGDRqoXbt2mj9/viTp6NGj2rJlix577DFJUnZ2tl5//XU1a9ZM3t7eqlSpktatW6f4+PgCHT8mJkY1atSwF1KSFBYWlmfe559/rjvuuEN+fn6qVKmSXn755QKf44/nCgkJsRdSktS+fXvl5OTo8OHD9rHGjRvL0dHR/trf31/JycmFOtcfzxkUFGQvpCSpUaNGqly5smJiYiRJY8eO1fDhw9WtWze9+eabOnr0qH3uM888o6lTp6p9+/aaNGmS9u/fX6QcBcWdUqWYj4eLPFyddP5ylo6dTlOwn4fVkQAAAAAAJZCbs6MOvtrTsnMXxrBhwzRq1Ci9//77WrBggWrWrKmuXbtKkt5++229++67mjlzppo2baqKFStqzJgxysjIKNCxDcPIM/bnRwu3b9+uv/3tb5oyZYp69uwpLy8vLV26VG+//XahPodhGNd8bPGP41cfnfvjezk5OYU6143O+cfxyZMn6+GHH9bq1av11VdfadKkSVq6dKnuu+8+DR8+XD179tTq1au1bt06TZs2TW+//bZGjx5dpDw3wp1SpZjNZrPfLXUk+bzFaQAAAAAAJZXNZpN7BSdLtoKsJ/VHDzzwgBwdHbV48WJ9/PHHevTRR+3H2LJli/r27atHHnlEISEhqlOnjo4cOVLgYzdq1Ejx8fE6efKkfWzbtm255nz33XeqWbOmJk6cqNDQUNWrVy/PNwJWqFBB2dnXf2KpUaNG2rt3ry5evJjr2A4ODqpfv36BMxfG1c+XkJBgHzt48KBSUlLUsGFD+1j9+vX17LPPat26derfv78WLFhgfy8oKEgjRozQ8uXL9dxzz+k///nPLckqUUqVenWrs64UAAAAAKDsqFSpkh588EFNmDBBJ0+e1NChQ+3v1a1bV+vXr9fWrVsVExOjJ598UklJSQU+drdu3RQcHKzBgwdr37592rJliyZOnJhrTt26dRUfH6+lS5fq6NGjmjVrllasWJFrTq1atRQbG6u9e/fq9OnTSk9Pz3OugQMHytXVVUOGDNEPP/ygyMhIjR49WoMGDbKvJ1VU2dnZ2rt3b67t4MGD6tatm5o1a6aBAwdqz5492rFjhwYPHqxOnTopNDRUly5d0qhRoxQVFaW4uDh999132rlzp72wGjNmjL7++mvFxsZqz5492rhxY64yq7hRSpVyLHYOAAAAAChrhg0bpt9++03dunVTjRo17OMvv/yyWrZsqZ49e6pz587y8/NTv379CnxcBwcHrVixQunp6WrdurWGDx+u119/Pdecvn376tlnn9WoUaPUvHlzbd26VS+//HKuOQMGDNBdd92lLl26qHr16lqyZEmec7m7u+vrr7/W2bNndfvtt+v+++9X165dNXv27ML9MPJx4cIFtWjRItfWu3dv2Ww2rVy5UlWqVFHHjh3VrVs31alTR8uWLZMkOTo66syZMxo8eLDq16+vBx54QL169dKUKVMkXSm7Ro4cqYYNG+quu+5ScHCwPvjgg5vOey02I78HKsuw1NRUeXl5KSUlRZ6enlbHuWkbD53SY+G71MDPQ2vHdLQ6DgAAAACgBLh8+bJiY2NVu3Ztubq6Wh0HZdD1rrGCdi/cKVXK1a1+ZXHzX05fVHZOueoXAQAAAABAKUYpVcrdVsVNLk4OysjKUcLZNKvjAAAAAAAAFAilVCnn6GBTHRY7BwAAAAAApQylVBlQ7/fFzo9QSgEAAAAAgFKCUqoM4Bv4AAAAAABAaUMpVQb8r5Q6b3ESAAAAAEBJYhh8IRZujeK4tiilyoA/Pr6XwzfwAQAAAEC55+joKEnKyMiwOAnKqrS0K1+25uzsXORjOBVXGFinVrWKquDooLSMbB3/7ZJqeLtbHQkAAAAAYCEnJye5u7vr119/lbOzsxwcuCcFxcMwDKWlpSk5OVmVK1e2F6BFQSlVBjg7OugvPpUUk5iqQ0mplFIAAAAAUM7ZbDb5+/srNjZWcXFxVsdBGVS5cmX5+fnd1DEopcqIBn4eiklM1eGk8+rR+OYuCgAAAABA6VehQgXVq1ePR/hQ7JydnW/qDqmrKKXKiGA/D0nSoVMsdg4AAAAAuMLBwUGurq5WxwDyxUOlZcTVUupwEqUUAAAAAAAo+SilyoiGfp6SpNjTF5WelW1xGgAAAAAAgOujlCojfD1d5OXmrOwcQz8nX7A6DgAAAAAAwHVRSpURNpuNR/gAAAAAAECpQSlVhjSglAIAAAAAAKUEpVQZcvVOqRhKKQAAAAAAUMJRSpUh/7tTKtXiJAAAAAAAANdHKVWG1Pe9UkqdSk3XubQMi9MAAAAAAABcG6VUGeLh6qzbKrtJkg7xCB8AAAAAACjBKKXKGBY7BwAAAAAApQGlVBnTwP9KKXXwJOtKAQAAAACAksvSUmrOnDlq1qyZPD095enpqbCwMH311VfX3WfTpk1q1aqVXF1dVadOHc2dO9ektKVD4wAvSdKPiSkWJwEAAAAAALg2S0upwMBAvfnmm9q1a5d27dqlO++8U3379tWPP/6Y7/zY2Fj17t1bHTp0UHR0tCZMmKBnnnlGERERJicvuZr8Xkr9lHRBmdk5FqcBAAAAAADIn80wDMPqEH9UtWpV/fOf/9SwYcPyvPfCCy9o1apViomJsY+NGDFC+/bt07Zt2wp0/NTUVHl5eSklJUWenp7FlrukMAxDzaas0/nLWVrzTAc1Cih7nxEAAAAAAJRcBe1eSsyaUtnZ2Vq6dKkuXryosLCwfOds27ZNPXr0yDXWs2dP7dq1S5mZmfnuk56ertTU1FxbWWaz2dTI/8o/8B9P8ggfAAAAAAAomSwvpQ4cOKBKlSrJxcVFI0aM0IoVK9SoUaN85yYlJcnX1zfXmK+vr7KysnT69Ol895k2bZq8vLzsW1BQULF/hpLGvq4Ui50DAAAAAIASyvJSKjg4WHv37tX27dv11FNPaciQITp48OA159tstlyvrz59+Ofxq8aPH6+UlBT7lpCQUHzhS6jGvz+yxzfwAQAAAACAksrJ6gAVKlRQ3bp1JUmhoaHauXOn/vWvf+nf//53nrl+fn5KSkrKNZacnCwnJyd5e3vne3wXFxe5uLgUf/ASrPFtv5dSianKyTHk4JB/YQcAAAAAAGAVy++U+jPDMJSenp7ve2FhYVq/fn2usXXr1ik0NFTOzs5mxCsV/lK9kio4OehCepbizqZZHQcAAAAAACAPS0upCRMmaMuWLTp27JgOHDigiRMnKioqSgMHDpR05dG7wYMH2+ePGDFCcXFxGjt2rGJiYjR//nzNmzdP48aNs+ojlEjOjg5q6OchicXOAQAAAABAyWRpKXXq1CkNGjRIwcHB6tq1q77//nutXbtW3bt3lyQlJiYqPj7ePr927dpas2aNoqKi1Lx5c7322muaNWuWBgwYYNVHKLEasdg5AAAAAAAowSxdU2revHnXfT88PDzPWKdOnbRnz55blKjsuLrYOaUUAAAAAAAoiUrcmlIoHv/7Br4U+zcUAgAAAAAAlBSUUmVUAz9POdik0xcylHw+/4XjAQAAAAAArEIpVUa5VXBUPZ8ri53vP85i5wAAAAAAoGShlCrDmgVeWex8X8I5a4MAAAAAAAD8CaVUGRYSVFmStO/4OUtzAAAAAAAA/BmlVBnW/PdSav9xFjsHAAAAAAAlC6VUGRbs56EKTg5KuZSpuDNpVscBAAAAAACwo5Qqw5wdHdQ4wFMSj/ABAAAAAICShVKqjAsJrCxJ2sti5wAAAAAAoAShlCrjQoKufAPf/uMpFicBAAAAAAD4H0qpMq7Z73dK/XAiRZnZOdaGAQAAAAAA+B2lVBlX27uiPFydlJ6Vo59Onbc6DgAAAAAAgCRKqTLPwcFmX1dqXwKP8AEAAAAAgJKBUqocaBZ4dV2pc9YGAQAAAAAA+B2lVDkQElRZEt/ABwAAAAAASg5KqXKgxe+l1E+nzutCepa1YQAAAAAAAEQpVS74eLoqsIqbcgxpb/w5q+MAAAAAAABQSpUXrWpWkSTtjvvN4iQAAAAAAACUUuWGvZSKp5QCAAAAAADWo5QqJ1rWuFJKRcf9puwcw+I0AAAAAACgvKOUKica+HmoYgVHnU/P0pHk81bHAQAAAAAA5RylVDnh5Oig5jUqS2JdKQAAAAAAYD1KqXKkVQ0WOwcAAAAAACUDpVQ50pJv4AMAAAAAACUEpVQ50qJGFdlsUtyZNP16Pt3qOAAAAAAAoByjlCpHvNycVd/HQ5K0J567pQAAAAAAgHUopcoZHuEDAAAAAAAlAaVUORP6eym1I/asxUkAAAAAAEB5RilVzrSpU1WSdOBEii6mZ1mcBgAAAAAAlFeUUuVMYBV3BVZxU3aOoV08wgcAAAAAACxCKVUOtantLUn6/pczFicBAAAAAADlFaVUOXT1Eb7vWVcKAAAAAABYhFKqHAqrc+VOqX0J55SWwbpSAAAAAADAfJRS5VBgFTcFeLkqK8fQnrhzVscBAAAAAADlEKVUOWSz2dT297ulvo9lXSkAAAAAAGA+Sqly6uq6UttZ7BwAAAAAAFiAUqqcuvoNfPsSUnQ5M9viNAAAAAAAoLyhlCqnanq7y8/TVRnZOdoT/5vVcQAAAAAAQDlDKVVO2Ww2+yN8247yCB8AAAAAADAXpVQ51v4v1SRJ3/582uIkAAAAAACgvKGUKsfuqHellNqXcE4plzItTgMAAAAAAMoTSqlyLKCym+pUr6gcg2/hAwAAAAAA5qKUKufuqPv7I3xHeIQPAAAAAACYh1KqnLOXUqwrBQAAAAAATEQpVc61/Yu3HB1sij19Ucd/S7M6DgAAAAAAKCcopco5T1dnhQR6SeIRPgAAAAAAYB5KKeiOetUl8QgfAAAAAAAwD6UU1KHelXWlth49o5wcw+I0AAAAAACgPKCUgpoHVVbFCo46ezFDBxNTrY4DAAAAAADKAUopyNnRQWF/8ZYkbfrpV4vTAAAAAACA8oBSCpKkzsE+kqTIQ8kWJwEAAAAAAOWBpaXUtGnTdPvtt8vDw0M+Pj7q16+fDh8+fN19oqKiZLPZ8myHDh0yKXXZ1KXBlVJqT/xv+u1ihsVpAAAAAABAWWdpKbVp0yaNHDlS27dv1/r165WVlaUePXro4sWLN9z38OHDSkxMtG/16tUzIXHZdVtlNwX7eijHkDYf4RE+AAAAAABwazlZefK1a9fmer1gwQL5+Pho9+7d6tix43X39fHxUeXKlW9huvKnSwMfHT51XpGHktW3+W1WxwEAAAAAAGVYiVpTKiUlRZJUtWrVG85t0aKF/P391bVrV0VGRt7qaOVCl+Dqkq4sdp6dY1icBgAAAAAAlGUlppQyDENjx47VHXfcoSZNmlxznr+/vz788ENFRERo+fLlCg4OVteuXbV58+Z856enpys1NTXXhvy1qllFnq5O+i0tU3sTzlkdBwAAAAAAlGGWPr73R6NGjdL+/fv17bffXndecHCwgoOD7a/DwsKUkJCgGTNm5PvI37Rp0zRlypRiz1sWOTk6qGP96vpyf6IiDyWrVc0qVkcCAAAAAABlVIm4U2r06NFatWqVIiMjFRgYWOj927ZtqyNHjuT73vjx45WSkmLfEhISbjZumdYl+Mq38EUeTrY4CQAAAAAAKMssvVPKMAyNHj1aK1asUFRUlGrXrl2k40RHR8vf3z/f91xcXOTi4nIzMcuVTsHVZbNJP55M1anUy/L1dLU6EgAAAAAAKIMsLaVGjhypxYsX6//+7//k4eGhpKQkSZKXl5fc3NwkXbnT6cSJE1q4cKEkaebMmapVq5YaN26sjIwMLVq0SBEREYqIiLDsc5Ql1Sq5KCSwsvYmnNOGmFMa2Kam1ZEAAAAAAEAZZOnje3PmzFFKSoo6d+4sf39/+7Zs2TL7nMTERMXHx9tfZ2RkaNy4cWrWrJk6dOigb7/9VqtXr1b//v2t+AhlUo/GvpKkr388ZXESAAAAAABQVtkMwzCsDmGm1NRUeXl5KSUlRZ6enlbHKZGO/npBXd/eJGdHm3a/3F2ers5WRwIAAAAAAKVEQbuXErHQOUqWv1SvpLo+lZSZbSjyEAueAwAAAACA4kcphXz1tD/Cl2RxEgAAAAAAUBZRSiFfPRr5SZKiDv+qy5nZFqcBAAAAAABlDaUU8tUs0Ev+Xq5Ky8jWt0dOWx0HAAAAAACUMZRSyJfNZlOPRjzCBwAAAAAAbg1KKVxTz8ZXHuHbEHNKWdk5FqcBAAAAAABlCaUUrql17aqq7O6s39IytSP2rNVxAAAAAABAGUIphWtycnRQz98XPP/yQKLFaQAAAAAAQFlCKYXr6hMSIEn66kCiMnmEDwAAAAAAFBNKKVxX2zpV5V2xgn5Ly9TWo2esjgMAAAAAAMoISilcl5Ojg3o39ZckfbHvpMVpAAAAAABAWUEphRu6+gjf1z8mKT0r2+I0AAAAAACgLKCUwg2F1qwiP09Xnb+cpc0/nbY6DgAAAAAAKAMopXBDDg423d3syiN8X+7nET4AAAAAAHDzKKVQIPf8XkqtP3hKlzJ4hA8AAAAAANwcSikUSPOgygqq6qa0jGytjzlldRwAAAAAAFDKUUqhQGw2m+5rfpskKWL3cYvTAAAAAACA0o5SCgV2X8tASdKWI78qOfWyxWkAAAAAAEBpRimFAqtdraJa1ayiHENaufeE1XEAAAAAAEApRimFQhnw+91SEbtPyDAMi9MAAAAAAIDSilIKhXJ3M39VcHLQ4VPn9ePJVKvjAAAAAACAUopSCoXi5eas7o18JUmfs+A5AAAAAAAoIkopFNr9vz/Ct2rfSWVk5VicBgAAAAAAlEaUUii0DvWqqVolF529mKHIw8lWxwEAAAAAAKUQpRQKzcnRQQNa3SZJWrIj3uI0AAAAAACgNKKUQpE8dHsNSdKmn35Vwtk0i9MAAAAAAIDSpkilVEJCgo4f/98i1zt27NCYMWP04YcfFlswlGy1qlVU+7reMgzpv7sSrI4DAAAAAABKmSKVUg8//LAiIyMlSUlJSerevbt27NihCRMm6NVXXy3WgCi5Hmp95W6pZTsTlJnNgucAAAAAAKDgilRK/fDDD2rdurUk6b///a+aNGmirVu3avHixQoPDy/OfCjBejTyk3fFCko+n66Nh1jwHAAAAAAAFFyRSqnMzEy5uLhIkjZs2KB7771XktSgQQMlJiYWXzqUaBWcHHR/aKAkafH3LHgOAAAAAAAKrkilVOPGjTV37lxt2bJF69ev11133SVJOnnypLy9vYs1IEq2qwuebz7CgucAAAAAAKDgilRKTZ8+Xf/+97/VuXNnPfTQQwoJCZEkrVq1yv5YH8qHWtUq6o661WQY0qfcLQUAAAAAAArIZhiGUZQds7OzlZqaqipVqtjHjh07Jnd3d/n4+BRbwOKWmpoqLy8vpaSkyNPT0+o4ZcLXPybpyU92q7K7s7a92FVuFRytjgQAAAAAACxS0O6lSHdKXbp0Senp6fZCKi4uTjNnztThw4dLdCGFW6NbQ18FVnHTubRMrdx7wuo4AAAAAACgFChSKdW3b18tXLhQknTu3Dm1adNGb7/9tvr166c5c+YUa0CUfI4ONg0JqyVJWvBdrIp48x0AAAAAAChHilRK7dmzRx06dJAkff755/L19VVcXJwWLlyoWbNmFWtAlA4P3B4k9wqO+unUBW09esbqOAAAAAAAoIQrUimVlpYmDw8PSdK6devUv39/OTg4qG3btoqLiyvWgCgdvNycNaBloCRpwXfHrA0DAAAAAABKvCKVUnXr1tXKlSuVkJCgr7/+Wj169JAkJScns3h4OTa0fS1J0jeHTinuzEVrwwAAAAAAgBKtSKXUK6+8onHjxqlWrVpq3bq1wsLCJF25a6pFixbFGhClx1+qV1Kn+tVlGNwtBQAAAAAArs9mFHFV6qSkJCUmJiokJEQODle6rR07dsjT01MNGjQo1pDFqaBfS4ii2fTTrxoyf4fcnB219cU7VaViBasjAQAAAAAAExW0eynSnVKS5OfnpxYtWujkyZM6ceKEJKl169YlupDCrdexXjU18vfUpcxsLdzG+mIAAAAAACB/RSqlcnJy9Oqrr8rLy0s1a9ZUjRo1VLlyZb322mvKyckp7owoRWw2m0Z0/oskKXxrrNIysixOBAAAAAAASqIilVITJ07U7Nmz9eabbyo6Olp79uzRG2+8offee08vv/xycWdEKdO7iZ9qVHXXb2mZ+u/OBKvjAAAAAACAEqhIa0oFBARo7ty5uvfee3ON/9///Z+efvpp++N8JRFrSplj0fY4vbTyB91W2U1R/+gsZ8ciPykKAAAAAABKkVu6ptTZs2fzXTuqQYMGOnv2bFEOiTLm/laBqlapgk6cu6Qv9p20Og4AAAAAAChhilRKhYSEaPbs2XnGZ8+erWbNmt10KJR+rs6OerR9bUnS3E1HlZNTpC95BAAAAAAAZZRTUXZ66623dPfdd2vDhg0KCwuTzWbT1q1blZCQoDVr1hR3RpRSj7StqbmbjuqnUxe05odE3dMswOpIAAAAAACghCjSnVKdOnXSTz/9pPvuu0/nzp3T2bNn1b9/f/34449asGBBcWdEKeXl5qxhd1y5W+pfG44om7ulAAAAAADA74q00Pm17Nu3Ty1btlR2dnZxHbLYsdC5uVIvZ+qONzcq9XKWZj3UQveGcLcUAAAAAABl2S1d6BwoKE9XZw3vUEeS9K8NP3G3FAAAAAAAkEQpBRM82r6WvNycdfTXi/pyP9/EBwAAAAAALC6lpk2bpttvv10eHh7y8fFRv379dPjw4Rvut2nTJrVq1Uqurq6qU6eO5s6da0JaFJWHq7Me7/D72lLfsLYUAAAAAAAo5Lfv9e/f/7rvnzt3rlAn37Rpk0aOHKnbb79dWVlZmjhxonr06KGDBw+qYsWK+e4TGxur3r176/HHH9eiRYv03Xff6emnn1b16tU1YMCAQp0f5hnavrY++jZWv/x6URG7j+uB24OsjgQAAAAAACxUqIXOH3300QLNK+o38P3666/y8fHRpk2b1LFjx3znvPDCC1q1apViYmLsYyNGjNC+ffu0bdu2G56Dhc6t85/Nv+j1NTHy83RV5LjOcqvgaHUkAAAAAABQzAravRTqTqmilk0FlZKSIkmqWrXqNeds27ZNPXr0yDXWs2dPzZs3T5mZmXJ2dr6lGVF0g8JqKnzrMZ04d0kLtsbq6c51rY4EAAAAAAAsUmIWOjcMQ2PHjtUdd9yhJk2aXHNeUlKSfH19c435+voqKytLp0+fzjM/PT1dqampuTZYw9XZUc/1qC9JmhN1VL9dzLA4EQAAAAAAsEqJKaVGjRql/fv3a8mSJTeca7PZcr2++gTin8elK4upe3l52begINYyslK/5repob+nzl/O0uzIn62OAwAAAAAALFIiSqnRo0dr1apVioyMVGBg4HXn+vn5KSkpKddYcnKynJyc5O3tnWf++PHjlZKSYt8SEhKKNTsKx8HBpvG9GkiSPtkWp4SzaRYnAgAAAAAAVrC0lDIMQ6NGjdLy5cu1ceNG1a5d+4b7hIWFaf369bnG1q1bp9DQ0HzXk3JxcZGnp2euDdbqWL+67qhbTRnZOXpz7SGr4wAAAAAAAAtYWkqNHDlSixYt0uLFi+Xh4aGkpCQlJSXp0qVL9jnjx4/X4MGD7a9HjBihuLg4jR07VjExMZo/f77mzZuncePGWfERUEQTejeUg01avT9R2385Y3UcAAAAAABgMktLqTlz5iglJUWdO3eWv7+/fVu2bJl9TmJiouLj4+2va9eurTVr1igqKkrNmzfXa6+9plmzZmnAgAFWfAQUUaMATz3cpoYkafKqH5WVnWNxIgAAAAAAYCabcXWV8HIiNTVVXl5eSklJ4VE+i/12MUOdZ0Qp5VKmXuvbWIPCalkdCQAAAAAA3KSCdi8lYqFzlE9VKlbQuB71JUkz1v2k3y5mWJwIAAAAAACYhVIKlnqodQ018PNQyqVMvb3+sNVxAAAAAACASSilYCknRwdNvrexJGnx9/Hal3DO2kAAAAAAAMAUlFKwXNs63rqvxW3KMaQXlx9QJoueAwAAAABQ5lFKoUR46e6GquzurJjEVM3/NtbqOAAAAAAA4BajlEKJ4F3JRRN7N5QkvbvhJ8WfSbM4EQAAAAAAuJUopVBi3N8qUGF1vHU5M0cTVx6QYRhWRwIAAAAAALcIpRRKDJvNpjf6N1UFJwdtOXJaK6JPWB0JAAAAAADcIpRSKFFqV6uov3etJ0ma8sVBnUq9bHEiAAAAAABwK1BKocR5omMdNb3NSymXMvVCxH4e4wMAAAAAoAyilEKJ4+zooHceCFEFJwdFHf5Vy3YmWB0JAAAAAAAUM0oplEj1fD30jx7BkqTXvjyohLN8Gx8AAAAAAGUJpRRKrMfuqK3WtarqYka2xn22Tzk5PMYHAAAAAEBZQSmFEsvRwaZ//rWZ3Cs46vvYs/pwyy9WRwIAAAAAAMWEUgolWk3viprUp5EkacbXh7Un/jeLEwEAAAAAgOJAKYUS74HQIPUJCVBWjqFnlkQr5VKm1ZEAAAAAAMBNopRCiWez2fT6fU1Uo6q7jv92SROWH5BhsL4UAAAAAAClGaUUSgVPV2e991ALOTnYtPpAohbviLc6EgAAAAAAuAmUUig1QoIq64W7GkiSpnxxUPuPn7M2EAAAAAAAKDJKKZQqw+6orW4NfZWRlaMRn+zWmQvpVkcCAAAAAABFQCmFUsXBwaZ3HgxRnWoVdTLlskYviVZWdo7VsQAAAAAAQCFRSqHU8XR11r8HtZJ7BUdtPXpGb3192OpIAAAAAACgkCilUCrV8/XQjL+GSJI+3PyLvth30uJEAAAAAACgMCilUGr1buqvEZ3+Ikka99k+7U04Z20gAAAAAABQYJRSKNX+0TNYXRv4KD0rR8M/3qXjv6VZHQkAAAAAABQApRRKNUcHm/71UAs19PfU6Qvpeix8p1IvZ1odCwAAAAAA3AClFEq9Si5Omj80VD4eLvrp1AWNWsw38gEAAAAAUNJRSqFM8Pdy07wht8vN2VGbf/pVL638QYZhWB0LAAAAAABcA6UUyoymgV7619+ay8EmLd2ZoBnrDlsdCQAAAAAAXAOlFMqUHo399Pp9TSVJ70ce1UdbfrE4EQAAAAAAyA+lFMqch1rX0D96BkuSpq6OUcTu4xYnAgAAAAAAf0YphTLp6c5/0fA7akuSno/Yr/UHT1mcCAAAAAAA/BGlFMokm82mCb0bakDLQGXnGBr56R5FHkq2OhYAAAAAAPgdpRTKLAcHm6YP+P/27jxOqurO+/j31tLVe9ELvbE2iiKgiOCCEgmSUdGQITEZdVDRzBNDDIoyjsZJ8mi2wddrHONkXPLEcUmCCQkP4GDiYwQ14IIiS2uzirGhoem2aWh6pau6qs7zRy1d1V0FzdJdvXzer1e97r3nnnPrVyUHX36999T5uu78Inn9AX176Wb9dTfBFAAAAAAAfQGhFAY0h92m/7xpsq6dUCSvL6A7f7tZ6z85lOyyAAAAAAAY9AilMOA57Tb91z9O1tXjC+X1BfSt32zS23sIpgAAAAAASCZCKQwKTrtNT/7jRfrSeYXy+AL6p19v0loWPwcAAAAAIGkIpTBopDhsenreRZE7pr69dLNWbT2Q7LIAAAAAABiUCKUwqISDqa9dNEz+gNF9f/hIv92wN9llAQAAAAAw6BBKYdBx2G167OuTdPvloyVJP/yf7XryzT0yxiS3MAAAAAAABhFCKQxKNpulh+eM1z2zxkqSHnv9Ez28ert8/kCSKwMAAAAAYHAglMKgZVmWFv/dOfrfXx4vy5J+s2Gfvv3bzWrx+JJdGgAAAAAAAx6hFAa9b04v1dP/eJFcDpve2FWrG3+1QbWNbckuCwAAAACAAY1QCpA0+/xi/f7Oy5SbkaJtVY366tPvaXdNU7LLAgAAAABgwCKUAkIuGpmjVXddrtL8DFUdPaavPf2u/rK9JtllAQAAAAAwIBFKAVFG5WVo5Xcu12VjctXi9evbv92sx9d8okCAX+YDAAAAAOBMIpQCOsnJSNFv/+lS3XHFaEnSL97Yozt/u0mNbe3JLQwAAAAAgAGEUAqIw2m36eE5E/TYNyYpxWHT2p21mvvUu9rzOetMAQAAAABwJhBKAcfx9SnDtfzb01TsTtVnh1o058l39MdN+2UMj/MBAAAAAHA6CKWAE5g0YohWL5yuL4zNV1t7QA/834/1z3/8SC0eX7JLAwAAAACg3yKUArphaJZLv77jEt1/9TmyWdLKrVX6ypPvaGd1Y7JLAwAAAACgXyKUArrJZrO08Kqx+v23LlNhtkt/O9Siv3/qXT33TgW/zgcAAAAAwElKaii1fv16zZkzRyUlJbIsSy+//PJx+//1r3+VZVldXrt27eqdggFJl47J06v3fEEzzx0qry+gn/xph+b99weqOnos2aUBAAAAANBvJDWUamlp0aRJk/Tkk0+e1Ljdu3eruro68ho7dmwPVQjEl5fp0vO3X6yfzJ2oNKddGz47rGt/vl4rNh9gEXQAAAAAALrBkcw3nz17tmbPnn3S4woKCjRkyJAzXxBwEizL0q2XjdL0s/O1+I9l2lp5VP+8/CO9vqNGP/n7iSrITk12iQAAAAAA9Fn9ck2pyZMnq7i4WLNmzdJbb7113L4ej0eNjY0xL+BMKs3P0PJvT9O/XHOuHDZLf9n+uWY9vk6/31jJWlMAAAAAACTQr0Kp4uJi/epXv9KKFSu0cuVKnXvuuZo1a5bWr1+fcMySJUvkdrsjrxEjRvRixRgsHHabvjvzbP3Pwit0/jC3mtp8emhluW569n397VBzsssDAAAAAKDPsUwfWQDHsiytWrVKc+fOPalxc+bMkWVZWr16ddzzHo9HHo8nctzY2KgRI0aooaFB2dnZp1MyEJfPH9CL7+3Vf7z+iY61+5XisOnumWfrzhlj5HLYk10eAAAAAAA9qrGxUW63+4TZS7+6Uyqeyy67THv27El43uVyKTs7O+YF9CSH3ab/9YUxev2+K3XlOcFf6PuPNZ/o2ife1lu7a5NdHgAAAAAAfUK/D6W2bt2q4uLiZJcBdDEiN12/vuNi/edNFyo/06WKuhbd8cKH+qcXP9TeupZklwcAAAAAQFIl9df3mpub9emnn0aOKyoqVFZWptzcXI0cOVIPPfSQqqqq9Jvf/EaS9MQTT2j06NGaMGGCvF6vli5dqhUrVmjFihXJ+gjAcVmWpb+/cJhmjivQf72xRy+8u1dv7KrV23vq9K0rS3XXF89Whiup0xAAAAAAgKRI6n8Nb9q0STNnzowcL168WJI0f/58vfjii6qurlZlZWXkvNfr1f3336+qqiqlpaVpwoQJ+vOf/6zrrruu12sHTkZ2qlPfv368brx4hH70yg69vadOT731N/1x0wHd+6WxunHqCDns/f7GRQAAAAAAuq3PLHTeW7q72BbQU4wxen3H5/rpn3do/5FjkqQxQzP0wDXjdM2EQlmWleQKAQAAAAA4dd3NXgilgCTx+Px66f1K/debe1Tf2i5JmjIqRw/NHqepo3OTXB0AAAAAAKeGUCoBQin0NY1t7fo/6/6m596pUFt7QJL0xXOHatGssZo8MifJ1QEAAAAAcHIIpRIglEJfVdPQpifWfqLlmw/IHwhOS8IpAAAAAEB/QyiVAKEU+rq9dS168q1PtWprFeEUAAAAAKDfIZRKgFAK/UW8cOrys/L07Rln6cqx+SyIDgAAAADokwilEiCUQn8TL5waV5SlBTPO0vUXFMtptyW5QgAAAAAAOhBKJUAohf7qQH2rnn9nr5Z9WKlWr1+SNGxImr45vVQ3XjxCmS5HkisEAAAAAIBQKiFCKfR3R1u9Wvr+Pr343l7VNXslSVkuh26YMly3TRulMUMzk1whAAAAAGAwI5RKgFAKA0Vbu18rt1Tpv9/+TJ/VtUTarzxnqOZPG6Uvnlsgu411pwAAAAAAvYtQKgFCKQw0gYDRO5/W6dfv7dWbu2sVntEjc9N1y2UjdcNFw5WX6UpukQAAAACAQYNQKgFCKQxklYdbtfSDffrDh/vVcKxdkuS0W/q78YW68eKRmn52PndPAQAAAAB6FKFUAoRSGAyOef36n7Iq/W5jpT4+0BBpL3Gn6htTR+gbU4dreE56EisEAAAAAAxUhFIJEEphsNlxsFF/3LRfq7ZWRe6esizpirPyNXfyMF0zoVBZqc4kVwkAAAAAGCgIpRIglMJg1dbu11+21+iPm/br3U8PR9pdDpu+NL5Qcy8cphnnDFWKw5bEKgEAAAAA/R2hVAKEUkBw7amXy6r0clmVPjvU8ct97jSnrju/WHMvLNHFo3NlY/0pAAAAAMBJIpRKgFAK6GCM0baqRr1cVqVXPjqo2iZP5NzQLJeumVCo2ROLdWlprhx27qACAAAAAJwYoVQChFJAfP6A0fufHdbLW6v02vYaNbX5Iudy0p36u/GFmn1+sa44K59H/AAAAAAACRFKJUAoBZyY1xfQu3+r02vlNXp9R43qW9sj57JSHZo1rkCzzivUlecMlTuNRdIBAAAAAB0IpRIglAJOjs8f0MaKI/p/22r0l+01MY/42W2Wpo7K0azzCnTVuEKdNTRDlsU6VAAAAAAwmBFKJUAoBZy6QMBoS2W91uz8XG/urNWe2uaY8yNz03XVuAJdNa5Al5TmKtVpT1KlAAAAAIBkIZRKgFAKOHMqD7fqzV2f641dtfrgsyPy+gORcy6HTZeU5mr62fmaPjZf5xVl82t+AAAAADAIEEolQCgF9IwWj0/vfFqnN3fW6q3dtTGP+UlSfmaKLj8rGFB9YWy+it1pSaoUAAAAANCTCKUSIJQCep4xRntqm/X2njq9s+eQ3v/siI61+2P6nDU0Q5eOydOlpbm6tDRPRe7UJFULAAAAADiTCKUSIJQCep/XF9CWynq9s6dOb39ap/IDRxXo9DfPqLx0XTI6NxJUDc9JY9F0AAAAAOiHCKUSIJQCkq+htV3vVxzWxooj+qDisHYcbOwSUpW4U3VJaa6mjM7V5BFDNK4oSw67LTkFAwAAAAC6jVAqAUIpoO9pbGvX5r31+qDiiDZWHNbHBxrk65RSpTntumC4W5NH5mjyyCGaPHKICrJ45A8AAAAA+hpCqQQIpYC+r9Xr09bKo/qg4oi2VtarbP9RNbX5uvQbnpOmySNzdOGIITp/mFsTSrKV4XIkoWIAAAAAQBihVAKEUkD/EwgY/e1Qs7ZWHtWWynptrTyqT2qb1PlvL8uSxuRn6Pxhbk0c5g4GVcPcyiSoAgAAAIBeQyiVAKEUMDA0tbXr4wMN2rKvXh8daNC2qgbVNLZ16WdZUmkoqDp/mFvjS7J1XlG2cjJSklA1AAAAAAx8hFIJEEoBA9ehJo+2VTWoPPTaVtWg6oauQZUkFWa7NK4oW+OKszSuKEvjirJ11tBMpThYTB0AAAAATgehVAKEUsDgUtfsCQZUB4JB1a6aJlUeaY3b12GzdHZBpsYVZencomyNK8rS2QWZGjYkTTab1cuVAwAAAED/RCiVAKEUgGaPT7trmrSrplG7qpu0u6ZJO2sa4y6mLgV/+W/M0AydXZCps4dmBrcFmRqVl8GdVQAAAADQCaFUAoRSAOIxxuhgQ5t2VTdqV02TdtU0aXdNoyrqWtTuj//XpN1maVReeiSoOmtopkbnZ6g0P0M56U5ZFndXAQAAABh8CKUSIJQCcDJ8/oAqj7Tq09pmfXqoWZ/WNutvtcFti9efcFxWqkOl+RkanZeh0fkZGp2XHgys8jJYZB0AAADAgEYolQChFIAzwRijmsa2YFgVen12qEX7DrfoYILF1cPcac5ISDU6L0MjctM1IidNI3LTVZidKjvrVwEAAADoxwilEiCUAtDT2tr92ne4VRV1wZBq7+EWVdS1aG9dq2oajx9YOe2WSoakaUROuoaHgqro7dBMF48FAgAAAOjTupu9OHqxJgAYFFKddp1blKVzi7K6nDvm9WvfkRbtrWtRRV2r9h1u0f76Vu0/ckwHjx5Tu99o3+FW7Tsc/xcCU502DQ8FVsNz0lTsTlPJkNTg1p2mQrdLLoe9pz8iAAAAAJw2QikA6EVpKXaNK8rWuKKu/7fA5w/o8yaP9h9p1f4jrTpQf0z761t14MgxHahvVXVjm9raA5HHBRPJz3SFgqrU2NBqSKpKhqSpIItHBAEAAAAkH4/vAUA/4fUFdPDosZg7qw42HFP10TZVNxzTwYY2eX2BE17HbrNUmOVSQXaqCrNdKsjq2BZEbXPTU2QjvAIAAABwknh8DwAGmBSHLbg4en5G3PPGGB1p8aq6oU0Hjx4LbqNDq6Nt+ryxTb6A0cGGthMuyO6wWRoaCq8KslwdwVWWS4XZqcrPdCkvM0V5mSk8MggAAADgpBFKAcAAYVmW8jJdyst0aeIwd9w+/oBRXbNHB48e0+eNHh1qalNtk0efN4a3wba6Zq98AaPqhjZVnyC8kqSsVEcwpMoIhlT5oTryw/sZKcrLdGlopkvZaQ4WawcAAABAKAUAg4ndZqkwO1WF2anH7dfuD6iuORhS1Ta26fMmjw41xgZYh5u9OtziUbvfqKnNp6Y2nyrqWk5Yg9NuKTcjGFblZqRoSHqKctOdGpKeopx0p3IyUpSTHnwNCR1npNgJsgAAAIABhlAKANCF025TsTv4637HY4xR4zGf6lqCIVVds0eHmz2qCwVWdU3B7eFmrw41e9TU5lO73+jzxmDg1V0pdlswoAoFVeEwKyfUlpORoiFpTrnTncpOdcqd5lR2mkNpTsIsAAAAoK8ilAIAnDLLsuROD4ZBZw09cX+Pz68jLd5ISFXf4lV9a3to69XR1nYdid5v9crrC8jrD6i2yaPapu4HWVLwrix3WjCoyk4LvtxpTrnTHJHwyh3VHt2WmergVwoBAACAHkQoBQDoNS6HvVt3YIUZY3Ss3R8JrsJB1dFWr+pb2lXf6g292tXQ6lVjm08Nx9rVcKxd/oBRu9+ortmrumbvKdWb6XIoK9WhTJdDmaFt5NgVDK6y4553Ro4zXYRbAAAAQDyEUgCAPsuyLKWnOJSe4tCwId0LsqRgmNXq9UcCqsbwNiq0agy/2tqj2oLnj7X7JUnNHp+aPb7T/hwZKfaOkCrVqSyXQxkuuzJSHMpwOZQe2k9PsQePU0LHkT52pac4Im1Ou+20awIAAACSjVAKADDgWJalDFcw8Ck5iTArzOsLqLGtXc1twVAqer/ZE1zUvdnji7QFF3pvj5xvbvOpyeOT1xeQJLV4/Wrx+vW5Tu7xw0RSHDZlpISCKlenbYpd6S5H3PNpTrtSncFteopDaSm2yHFail2pDrts3NUFAACAXkIoBQBAJykOm/IzXcrPdJ3WdTw+v1o8/lBI1R4Ms0L7LR6/Wr2+jq3Xr1ZPcNvi6Thu9frV4vWp1eOX1x8Muby+gLy+gOpb28/Ex42R6rQFQ6pQUJWW0hFmpadEBViRcCu0n9Lp2Bk7NtVpl8tpU6rDLqfdYgF6AAAAEEoBANBTXA67XA67cjNSzsj1vL6AjoVDKq9PzZ6OICsm4IoEXcEwq9nj07F2v455/cFt9L7XL0/oji5JamsPqK09oHqd+cArzLKkVEdHSBVv6zrB+VSHTS6nXamhvom2LodNKeGX3SYHjz4CAAD0GYRSAAD0E+FwxZ3uPKPX9QeM2qLCqvB+ayi4avN2HLcdJ9zqHHxFj4sOvoxRpI96MPyKx2YpElClhEIrp92KCa6C+3al2G2RUCvSx26P9HXF9LfJae+4RucwzGkPXsNpt8npsMlp69h32Cyl2G08OgkAAAYdQikAAAY5u61jDa6eYoyR1x+8C8vj88sT2rYdb9vuV5svIE97QG2hMZ23ngTt0VtjOuoImI67waTTX8T+TLJZCgZbdpsc4QArOszqtO+wWzF9uzsuvO8I7afE2XfYLTltNtltlpx2K7QNHjvslhw2W2gb2rdZhGoAAOCkJTWUWr9+vf793/9dmzdvVnV1tVatWqW5c+ced8y6deu0ePFibd++XSUlJXrggQe0YMGC3ikYAACcEsuyIo8zSmf2Tq/jMcbIFzDy+gJq9wfX4vL4AvKG9r0nse+JukbnPh3X9Kvdb7qcb/eHXyZ4DX8gJiyTgoGZJ3St/shmKRJWRYdYTpsle1TI5bAHQ6yYUCu8HzkX2kaFYB0Bma1rUGZLMD50XZsV3LdZwWvZbApdU7LbbLJbVtw2u90Kbm2xr8g1CeMAADgtSQ2lWlpaNGnSJN1xxx264YYbTti/oqJC1113nb71rW9p6dKlevfdd3XXXXdp6NCh3RoPAAAGF8uyIncG9TX+gImEVb6osOpE+9Hhls8fvAMt3n7XcV3HJxrXHgjI7zdqD5hInf6Akc9v5AsEFDBdP0/AKBjC+Xv/u0y2cDhljwqqYrahUCxewGUPjQv3jW5L1NduC/5YgN0m2a3wviWbpUgdttA1bZYi17eFxtis8P5xxoT6h8dYVvR7dz4f7zqKOtfpmpF+6qir0xgrVHf4swIABqakhlKzZ8/W7Nmzu93/l7/8pUaOHKknnnhCknTeeedp06ZNeuyxxwilAABAvxIMGYK/TNjfBALBO9B8gUBw6zfy+aP2A8fZ98cGXcHgKxiUBYOv6P5Rx1HXiRnvD40PGPkTvZ8xkZr94ZeJ2u/c7o8974uXwkXxBYziJnU4Y8KBXGwgFht0hQM4KyrgshTaWh1hXHi/oy0Yutmi+shSzHG8vp3HdL5u9BhbqC7rBNeNN8ZmSZY6QrzOfaSoY5sVU1fnz29ZwR+bsBTcV9T5cJslhc5FjQu1hfsp0q+jvvBYdTq22awu1wyPja5Piq0tvG+zEo8N1xcZG12run7ezmMtWbJsCdq7fD+d+hCWAmdEv1pTasOGDbr66qtj2q655ho999xzam9vl9PZe48DAAAADFY2m6UUm6UU9b070HpKINA1qAoHXQETe+wPt/k7zsUNvwIB+QOKbIN3oZmYtuA29n2MUeQ6xoSvFXxcNfjeCl0nOCYQ3R5q80fvR/op4Ri/6TQ+akzHNY0Cgc7vHXXNTtfxG9PlMdZE/AEjvwj+0PfY4oRhHaFddKhnRYV2sSFk/NAuNhwLR2DRYVg4dAuNjNs30tuK3x6pWR3Xin4fK6o9Xl8r6sDq1B59jc7jY+uJc93j1BU9Lt57dfSP953EXjf6+1OXvp2/p67tih7f+XtRp+t3+nyxPWPH3jXzbA0bkqbBoF+FUjU1NSosLIxpKywslM/nU11dnYqLi7uM8Xg88ng8kePGxsYerxMAAAADi81mySZL/fDGtj7NmHghWijIigq7YoM4RQJCEycMMwruh69tQtcPhK4TiLTHHp/+mOi2qDEKHQfijFGnMYFOY4yJee9AIM6YuLXF1mRCQaQJpYAm6j3CY4wkRbeH/vkEv8/gIBNnbKRfgrGKun7nsdF/BmLHBgeGj8Of1cTUGV1fR994n6Enb2QMdBQc/lPdc2+GQePmS0YSSvVVnW+TDP/Fmuj2ySVLluhHP/pRj9cFAAAA4OQE16qS7AR+6AXGdA3NwqGcpITBmgkkaO8S0JkuQZ0UG5pFjw0Hb4EE1+moO7SNag9fq2M/0jumT+Rzxelrwule576K/j6ivruOt+haT4K+iepK9JnC46M/e0w9cfpG1xW/9gTvFe87ifs9da0pfD0pXk1d369j7InHSFJBlkuDRb8KpYqKilRTUxPTVltbK4fDoby8vLhjHnroIS1evDhy3NjYqBEjRvRonQAAAACAviX8yFzoKJmlAAjpV6HUtGnT9Morr8S0vf7665o6dWrC9aRcLpdcrsGTMgIAAAAAAPQHSV2dsrm5WWVlZSorK5MkVVRUqKysTJWVlZKCdznddtttkf4LFizQvn37tHjxYu3cuVPPP/+8nnvuOd1///3JKB8AAAAAAACnKKl3Sm3atEkzZ86MHIcfs5s/f75efPFFVVdXRwIqSSotLdWrr76q++67T0899ZRKSkr0i1/8QjfccEOv1w4AAAAAAIBTZxnTeemtga2xsVFut1sNDQ3Kzs5OdjkAAAAAAAADSnezl6Q+vgcAAAAAAIDBiVAKAAAAAAAAvY5QCgAAAAAAAL2OUAoAAAAAAAC9jlAKAAAAAAAAvY5QCgAAAAAAAL2OUAoAAAAAAAC9zpHsAnqbMUaS1NjYmORKAAAAAAAABp5w5hLOYBIZdKFUU1OTJGnEiBFJrgQAAAAAAGDgampqktvtTnjeMieKrQaYQCCggwcPKisrS5ZlJbuc09LY2KgRI0Zo//79ys7OTnY5QJ/GfAG6h7kCdA9zBeg+5gvQPQNprhhj1NTUpJKSEtlsiVeOGnR3StlsNg0fPjzZZZxR2dnZ/f4PLNBbmC9A9zBXgO5hrgDdx3wBumegzJXj3SEVxkLnAAAAAAAA6HWEUgAAAAAAAOh1hFL9mMvl0sMPPyyXy5XsUoA+j/kCdA9zBege5grQfcwXoHsG41wZdAudAwAAAAAAIPm4UwoAAAAAAAC9jlAKAAAAAAAAvY5QCgAAAAAAAL2OUKofe/rpp1VaWqrU1FRNmTJFb7/9drJLAs6IJUuW6OKLL1ZWVpYKCgo0d+5c7d69O6aPMUaPPPKISkpKlJaWpi9+8Yvavn17TB+Px6O7775b+fn5ysjI0Fe+8hUdOHAgpk99fb1uvfVWud1uud1u3XrrrTp69GhMn8rKSs2ZM0cZGRnKz8/XPffcI6/X2yOfHThdS5YskWVZuvfeeyNtzBcgqKqqSrfccovy8vKUnp6uCy+8UJs3b46cZ64AQT6fTz/4wQ9UWlqqtLQ0jRkzRj/+8Y8VCAQifZgvGIzWr1+vOXPmqKSkRJZl6eWXX44539fmRXl5uWbMmKG0tDQNGzZMP/7xj9XnlhU36JeWLVtmnE6nefbZZ82OHTvMokWLTEZGhtm3b1+ySwNO2zXXXGNeeOEFs23bNlNWVmauv/56M3LkSNPc3Bzp8+ijj5qsrCyzYsUKU15ebm688UZTXFxsGhsbI30WLFhghg0bZtasWWO2bNliZs6caSZNmmR8Pl+kz7XXXmsmTpxo3nvvPfPee++ZiRMnmi9/+cuR8z6fz0ycONHMnDnTbNmyxaxZs8aUlJSYhQsX9s6XAZyEjRs3mtGjR5sLLrjALFq0KNLOfAGMOXLkiBk1apS5/fbbzQcffGAqKirM2rVrzaeffhrpw1wBgn7605+avLw886c//clUVFSY5cuXm8zMTPPEE09E+jBfMBi9+uqr5vvf/75ZsWKFkWRWrVoVc74vzYuGhgZTWFhobrrpJlNeXm5WrFhhsrKyzGOPPdZzX9ApIJTqpy655BKzYMGCmLZx48aZ733ve0mqCOg5tbW1RpJZt26dMcaYQCBgioqKzKOPPhrp09bWZtxut/nlL39pjDHm6NGjxul0mmXLlkX6VFVVGZvNZl577TVjjDE7duwwksz7778f6bNhwwYjyezatcsYE/wXj81mM1VVVZE+v//9743L5TINDQ0996GBk9TU1GTGjh1r1qxZY2bMmBEJpZgvQNCDDz5opk+fnvA8cwXocP3115tvfvObMW1f+9rXzC233GKMYb4AxpguoVRfmxdPP/20cbvdpq2tLdJnyZIlpqSkxAQCgTP4TZweHt/rh7xerzZv3qyrr746pv3qq6/We++9l6SqgJ7T0NAgScrNzZUkVVRUqKamJmYOuFwuzZgxIzIHNm/erPb29pg+JSUlmjhxYqTPhg0b5Ha7demll0b6XHbZZXK73TF9Jk6cqJKSkkifa665Rh6PJ+aRDyDZvvvd7+r666/Xl770pZh25gsQtHr1ak2dOlXf+MY3VFBQoMmTJ+vZZ5+NnGeuAB2mT5+uN954Q5988okk6aOPPtI777yj6667ThLzBYinr82LDRs2aMaMGXK5XDF9Dh48qL179575L+AUOZJdAE5eXV2d/H6/CgsLY9oLCwtVU1OTpKqAnmGM0eLFizV9+nRNnDhRkiJ/zuPNgX379kX6pKSkKCcnp0uf8PiamhoVFBR0ec+CgoKYPp3fJycnRykpKcw39BnLli3Tli1b9OGHH3Y5x3wBgj777DM988wzWrx4sf71X/9VGzdu1D333COXy6XbbruNuQJEefDBB9XQ0KBx48bJbrfL7/frZz/7mW6++WZJ/LsFiKevzYuamhqNHj26y/uEz5WWlp7KxzzjCKX6McuyYo6NMV3agP5u4cKF+vjjj/XOO+90OXcqc6Bzn3j9T6UPkCz79+/XokWL9Prrrys1NTVhP+YLBrtAIKCpU6fq3/7t3yRJkydP1vbt2/XMM8/otttui/RjrgDSH/7wBy1dulS/+93vNGHCBJWVlenee+9VSUmJ5s+fH+nHfAG66kvzIl4ticYmC4/v9UP5+fmy2+1d/s9AbW1tl7QU6M/uvvturV69Wm+99ZaGDx8eaS8qKpKk486BoqIieb1e1dfXH7fP559/3uV9Dx06FNOn8/vU19ervb2d+YY+YfPmzaqtrdWUKVPkcDjkcDi0bt06/eIXv5DD4Yj5P2LRmC8YbIqLizV+/PiYtvPOO0+VlZWS+HcLEO1f/uVf9L3vfU833XSTzj//fN1666267777tGTJEknMFyCevjYv4vWpra2V1PVurmQilOqHUlJSNGXKFK1Zsyamfc2aNbr88suTVBVw5hhjtHDhQq1cuVJvvvlml1tLS0tLVVRUFDMHvF6v1q1bF5kDU6ZMkdPpjOlTXV2tbdu2RfpMmzZNDQ0N2rhxY6TPBx98oIaGhpg+27ZtU3V1daTP66+/LpfLpSlTppz5Dw+cpFmzZqm8vFxlZWWR19SpUzVv3jyVlZVpzJgxzBdA0hVXXKHdu3fHtH3yyScaNWqUJP7dAkRrbW2VzRb7n4p2u12BQEAS8wWIp6/Ni2nTpmn9+vXyer0xfUpKSro81pdUvbemOs6kZcuWGafTaZ577jmzY8cOc++995qMjAyzd+/eZJcGnLbvfOc7xu12m7/+9a+muro68mptbY30efTRR43b7TYrV6405eXl5uabb477c6vDhw83a9euNVu2bDFXXXVV3J9bveCCC8yGDRvMhg0bzPnnnx/351ZnzZpltmzZYtauXWuGDx/OzxCjT4v+9T1jmC+AMcZs3LjROBwO87Of/czs2bPHvPTSSyY9Pd0sXbo00oe5AgTNnz/fDBs2zPzpT38yFRUVZuXKlSY/P9888MADkT7MFwxGTU1NZuvWrWbr1q1Gknn88cfN1q1bzb59+4wxfWteHD161BQWFpqbb77ZlJeXm5UrV5rs7Gzz2GOP9cI31X2EUv3YU089ZUaNGmVSUlLMRRddZNatW5fskoAzQlLc1wsvvBDpEwgEzMMPP2yKioqMy+UyV155pSkvL4+5zrFjx8zChQtNbm6uSUtLM1/+8pdNZWVlTJ/Dhw+befPmmaysLJOVlWXmzZtn6uvrY/rs27fPXH/99SYtLc3k5uaahQsXxvy0KtDXdA6lmC9A0CuvvGImTpxoXC6XGTdunPnVr34Vc565AgQ1NjaaRYsWmZEjR5rU1FQzZswY8/3vf994PJ5IH+YLBqO33nor7n+nzJ8/3xjT9+bFxx9/bL7whS8Yl8tlioqKzCOPPGICgcAZ/15Oh2VMaKUrAAAAAAAAoJewphQAAAAAAAB6HaEUAAAAAAAAeh2hFAAAAAAAAHodoRQAAAAAAAB6HaEUAAAAAAAAeh2hFAAAAAAAAHodoRQAAAAAAAB6HaEUAAAAAAAAeh2hFAAAwABlWZZefvnlZJcBAAAQF6EUAABAD7j99ttlWVaX17XXXpvs0gAAAPoER7ILAAAAGKiuvfZavfDCCzFtLpcrSdUAAAD0LdwpBQAA0ENcLpeKiopiXjk5OZKCj9Y988wzmj17ttLS0lRaWqrly5fHjC8vL9dVV12ltLQ05eXl6c4771Rzc3NMn+eff14TJkyQy+VScXGxFi5cGHO+rq5OX/3qV5Wenq6xY8dq9erVPfuhAQAAuolQCgAAIEl++MMf6oYbbtBHH32kW265RTfffLN27twpSWptbdW1116rnJwcffjhh1q+fLnWrl0bEzo988wz+u53v6s777xT5eXlWr16tc4+++yY9/jRj36kf/iHf9DHH3+s6667TvPmzdORI0d69XMCAADEYxljTLKLAAAAGGhuv/12LV26VKmpqTHtDz74oH74wx/KsiwtWLBAzzzzTOTcZZddposuukhPP/20nn32WT344IPav3+/MjIyJEmvvvqq5syZo4MHD6qwsFDDhg3THXfcoZ/+9Kdxa7AsSz/4wQ/0k5/8RJLU0tKirKwsvfrqq6xtBQAAko41pQAAAHrIzJkzY0InScrNzY3sT5s2LebctGnTVFZWJknauXOnJk2aFAmkJOmKK65QIBDQ7t27ZVmWDh48qFmzZh23hgsuuCCyn5GRoaysLNXW1p7qRwIAADhjCKUAAAB6SEZGRpfH6U7EsixJkjEmsh+vT1paWreu53Q6u4wNBAInVRMAAEBPYE0pAACAJHn//fe7HI8bN06SNH78eJWVlamlpSVy/t1335XNZtM555yjrKwsjR49Wm+88Uav1gwAAHCmcKcUAABAD/F4PKqpqYlpczgcys/PlyQtX75cU6dO1fTp0/XSSy9p48aNeu655yRJ8+bN08MPP6z58+frkUce0aFDh3T33Xfr1ltvVWFhoSTpkUce0YIFC1RQUKDZs2erqalJ7777ru6+++7e/aAAAACngFAKAACgh7z22msqLi6OaTv33HO1a9cuScFfxlu2bJnuuusuFRUV6aWXXtL48eMlSenp6frLX/6iRYsW6eKLL1Z6erpuuOEGPf7445FrzZ8/X21tbfr5z3+u+++/X/n5+fr617/eex8QAADgNPDrewAAAElgWZZWrVqluXPnJrsUAACApGBNKQAAAAAAAPQ6QikAAAAAAAD0OtaUAgAASAJWUAAAAIMdd0oBAAAAAACg1xFKAQAAAAAAoNcRSgEAAAAAAKDXEUoBAAAAAACg1xFKAQAAAAAAoNcRSgEAAAAAAKDXEUoBAAAAAACg1xFKAQAAAAAAoNcRSgEAAAAAAKDX/X9f5GmAbHME5gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = {\n",
    "            'W1': np.random.uniform(-1, 1, size=(input_size, hidden_size)),\n",
    "            'W2': np.random.uniform(-1, 1, size=(hidden_size, output_size))\n",
    "        }\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights['W1'])\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights['W2'])\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = np.dot(2, self.z2) - y\n",
    "        dLoss_dW2 = np.dot(self.a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.weights['W2'].T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (self.a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "\n",
    "        self.weights['W2'] -= learning_rate * dLoss_dW2 \n",
    "        self.weights['W1'] -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the training data indices\n",
    "            indices = np.random.permutation(len(X_train))\n",
    "\n",
    "            # Perform mini-batch gradient descent\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                # Get the batch indices\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                \n",
    "                # Select the batch data using the shuffled indices\n",
    "                batch_X = X_train[batch_indices]\n",
    "                batch_y = y_train[batch_indices]\n",
    "\n",
    "                # Forward pass and loss calculation for the batch\n",
    "                batch_output = self.forward(batch_X)\n",
    "                batch_loss = np.mean(((batch_output - batch_y)/batch_y) ** 2)\n",
    "                train_loss_history.append(batch_loss)\n",
    "\n",
    "                #print(f'np.max(train_loss_history) = {np.max(train_loss_history)}')\n",
    "\n",
    "                self.backward(batch_X, batch_y, learning_rate)\n",
    "\n",
    "            # Forward pass and loss calculation for validation data\n",
    "            val_output = self.forward(X_val)\n",
    "            val_loss = np.mean((val_output - y_val) ** 2)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {batch_loss:.10f}, Val Loss: {val_loss:.10f}\")\n",
    "\n",
    "        return train_loss_history, val_loss_history\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "g = 9.80665  # Gravitational acceleration\n",
    "\n",
    "# Compute dimensionally homogeneous and normalized inputs/output\n",
    "c2 = data['speed']**2\n",
    "data['gh_c2'] = (g * data['height']) / c2\n",
    "data['gsl_c2'] = (g * np.sqrt(data['height'] * data['wave_length'])) / c2\n",
    "X = data[[\"gh_c2\", \"gsl_c2\"]].values\n",
    "y = (c2 / c2).values.reshape(-1, 1)  # Normalized target (always 1)\n",
    "\n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "num_epochs = 100000\n",
    "learning_rate = 0.000000001\n",
    "#learning_rate = 0.000000000000000001\n",
    "#learning_rate = 10e-6\n",
    "batch_size = 64\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "train_loss_history, val_loss_history = network.train(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 45384.8641\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c^2 = S(g\\sqrt{h^2+\\lambda^2}, \\frac{gh\\lambda}{h+\\lambda})$ ------------ $(m^2/s^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = {\n",
    "            'W1': np.random.uniform(-1, 1, size=(input_size, hidden_size)),\n",
    "            'W2': np.random.uniform(-1, 1, size=(hidden_size, output_size))\n",
    "        }\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights['W1'])\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights['W2'])\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = np.dot(2, self.z2) - y\n",
    "        dLoss_dW2 = np.dot(self.a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.weights['W2'].T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (self.a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "\n",
    "        self.weights['W2'] -= learning_rate * dLoss_dW2 \n",
    "        self.weights['W1'] -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the training data indices\n",
    "            indices = np.random.permutation(len(X_train))\n",
    "\n",
    "            # Perform mini-batch gradient descent\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                # Get the batch indices\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                \n",
    "                # Select the batch data using the shuffled indices\n",
    "                batch_X = X_train[batch_indices]\n",
    "                batch_y = y_train[batch_indices]\n",
    "\n",
    "                # Forward pass and loss calculation for the batch\n",
    "                batch_output = self.forward(batch_X)\n",
    "                batch_loss = np.mean(((batch_output - batch_y)/batch_y) ** 2)\n",
    "                train_loss_history.append(batch_loss)\n",
    "\n",
    "                #print(f'np.max(train_loss_history) = {np.max(train_loss_history)}')\n",
    "\n",
    "                self.backward(batch_X, batch_y, learning_rate)\n",
    "\n",
    "            # Forward pass and loss calculation for validation data\n",
    "            val_output = self.forward(X_val)\n",
    "            val_loss = np.mean((val_output - y_val) ** 2)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {batch_loss:.10f}, Val Loss: {val_loss:.10f}\")\n",
    "\n",
    "        return train_loss_history, val_loss_history\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "g = 9.80665  # Gravitational acceleration\n",
    "\n",
    "# Compute dimensionally homogeneous and normalized inputs/output\n",
    "c2 = data['speed']**2\n",
    "data['ghl_c2'] = (g * np.sqrt(data['height']**2 + data['wave_length']**2)) / c2\n",
    "data['gl_c2'] = (g * data['height'] * data['wave_length']) / (data['height'] + data['wave_length']) / c2\n",
    "X = data[[\"ghl_c2\", \"gl_c2\"]].values\n",
    "y = (c2 / c2).values.reshape(-1, 1)  # Normalized target (always 1)\n",
    "\n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "num_epochs = 100000\n",
    "learning_rate = 0.000000001\n",
    "#learning_rate = 0.000000000000000001\n",
    "#learning_rate = 10e-6\n",
    "batch_size = 64\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "train_loss_history, val_loss_history = network.train(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 45384.8641\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c = S(h,\\lambda)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000], Train Loss: 1.0901268834, Val Loss: 13282.3293730470\n",
      "Epoch [2000/100000], Train Loss: 0.3471583314, Val Loss: 13097.1631433990\n",
      "Epoch [3000/100000], Train Loss: 3.3705289960, Val Loss: 13352.9754918254\n",
      "Epoch [4000/100000], Train Loss: 0.5817707377, Val Loss: 12628.8041636351\n",
      "Epoch [5000/100000], Train Loss: 0.6193980832, Val Loss: 12601.4080542933\n",
      "Epoch [6000/100000], Train Loss: 0.7530043586, Val Loss: 12883.7429931433\n",
      "Epoch [7000/100000], Train Loss: 61.5902110831, Val Loss: 12427.1400728917\n",
      "Epoch [8000/100000], Train Loss: 0.5186940513, Val Loss: 13165.0977126552\n",
      "Epoch [9000/100000], Train Loss: 0.4866271899, Val Loss: 13334.8215641264\n",
      "Epoch [10000/100000], Train Loss: 0.4613036650, Val Loss: 12814.5369528341\n",
      "Epoch [11000/100000], Train Loss: 0.3631563387, Val Loss: 12740.3504739282\n",
      "Epoch [12000/100000], Train Loss: 0.4442441082, Val Loss: 12834.8378777002\n",
      "Epoch [13000/100000], Train Loss: 3.5333133168, Val Loss: 13688.9614839963\n",
      "Epoch [14000/100000], Train Loss: 0.3895145673, Val Loss: 12554.3604601798\n",
      "Epoch [15000/100000], Train Loss: 1.2819423737, Val Loss: 12846.3494424863\n",
      "Epoch [16000/100000], Train Loss: 59.0952625406, Val Loss: 12998.3007019148\n",
      "Epoch [17000/100000], Train Loss: 0.3281713749, Val Loss: 13143.4488039715\n",
      "Epoch [18000/100000], Train Loss: 0.9660820078, Val Loss: 13076.0175928136\n",
      "Epoch [19000/100000], Train Loss: 0.7255558375, Val Loss: 12957.5372194990\n",
      "Epoch [20000/100000], Train Loss: 0.4601823227, Val Loss: 12483.7973064186\n",
      "Epoch [21000/100000], Train Loss: 0.5168954220, Val Loss: 12805.4185583532\n",
      "Epoch [22000/100000], Train Loss: 0.3194835686, Val Loss: 13111.8068360930\n",
      "Epoch [23000/100000], Train Loss: 0.2904132073, Val Loss: 12803.7592743382\n",
      "Epoch [24000/100000], Train Loss: 0.3397698204, Val Loss: 13007.3328482331\n",
      "Epoch [25000/100000], Train Loss: 0.5731118095, Val Loss: 12978.4412564368\n",
      "Epoch [26000/100000], Train Loss: 1.5562603672, Val Loss: 12874.2695833653\n",
      "Epoch [27000/100000], Train Loss: 59.1168805125, Val Loss: 12924.8789121831\n",
      "Epoch [28000/100000], Train Loss: 103.7480766477, Val Loss: 12617.5452334412\n",
      "Epoch [29000/100000], Train Loss: 0.4057939787, Val Loss: 13358.6994840974\n",
      "Epoch [30000/100000], Train Loss: 0.7372105053, Val Loss: 12359.0521777059\n",
      "Epoch [31000/100000], Train Loss: 58.3593055700, Val Loss: 13689.8598178848\n",
      "Epoch [32000/100000], Train Loss: 3.0467622223, Val Loss: 13162.1369538329\n",
      "Epoch [33000/100000], Train Loss: 0.3852509934, Val Loss: 12957.0261239856\n",
      "Epoch [34000/100000], Train Loss: 0.4560432103, Val Loss: 12589.2902485594\n",
      "Epoch [35000/100000], Train Loss: 105.7105944019, Val Loss: 13038.1355785890\n",
      "Epoch [36000/100000], Train Loss: 0.9734188927, Val Loss: 12997.1546732173\n",
      "Epoch [37000/100000], Train Loss: 0.4048036206, Val Loss: 12672.1482972820\n",
      "Epoch [38000/100000], Train Loss: 1.4574391188, Val Loss: 13353.6472984936\n",
      "Epoch [39000/100000], Train Loss: 0.4333881573, Val Loss: 12523.4410279657\n",
      "Epoch [40000/100000], Train Loss: 0.3666399770, Val Loss: 12827.1386823733\n",
      "Epoch [41000/100000], Train Loss: 0.7685817175, Val Loss: 12591.8450430498\n",
      "Epoch [42000/100000], Train Loss: 10.5688129893, Val Loss: 12950.8766056974\n",
      "Epoch [43000/100000], Train Loss: 1.3100655327, Val Loss: 12826.7591808013\n",
      "Epoch [44000/100000], Train Loss: 60.4970302486, Val Loss: 12707.4837165949\n",
      "Epoch [45000/100000], Train Loss: 9.5022030153, Val Loss: 13198.6128255439\n",
      "Epoch [46000/100000], Train Loss: 4.7494908812, Val Loss: 12561.7129321707\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     91\u001b[0m network \u001b[38;5;241m=\u001b[39m ShallowReLUNetwork(input_size, hidden_size, output_size)\n\u001b[0;32m---> 92\u001b[0m train_loss_history, val_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Plot the training and validation loss\u001b[39;00m\n\u001b[1;32m     95\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "Cell \u001b[0;32mIn[95], line 53\u001b[0m, in \u001b[0;36mShallowReLUNetwork.train\u001b[0;34m(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m y_train[batch_indices]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Forward pass and loss calculation for the batch\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(((batch_output \u001b[38;5;241m-\u001b[39m batch_y)\u001b[38;5;241m/\u001b[39mbatch_y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     55\u001b[0m train_loss_history\u001b[38;5;241m.\u001b[39mappend(batch_loss)\n",
      "Cell \u001b[0;32mIn[95], line 21\u001b[0m, in \u001b[0;36mShallowReLUNetwork.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz2\n",
      "Cell \u001b[0;32mIn[95], line 16\u001b[0m, in \u001b[0;36mShallowReLUNetwork.relu\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size \u001b[38;5;241m=\u001b[39m output_size\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(input_size, hidden_size)),\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(hidden_size, output_size))\n\u001b[1;32m     14\u001b[0m     }\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, x)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = {\n",
    "            'W1': np.random.uniform(-1, 1, size=(input_size, hidden_size)),\n",
    "            'W2': np.random.uniform(-1, 1, size=(hidden_size, output_size))\n",
    "        }\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights['W1'])\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights['W2'])\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = np.dot(2, self.z2) - y\n",
    "        dLoss_dW2 = np.dot(self.a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.weights['W2'].T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (self.a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "\n",
    "        self.weights['W2'] -= learning_rate * dLoss_dW2 \n",
    "        self.weights['W1'] -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the training data indices\n",
    "            indices = np.random.permutation(len(X_train))\n",
    "\n",
    "            # Perform mini-batch gradient descent\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                # Get the batch indices\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                \n",
    "                # Select the batch data using the shuffled indices\n",
    "                batch_X = X_train[batch_indices]\n",
    "                batch_y = y_train[batch_indices]\n",
    "\n",
    "                # Forward pass and loss calculation for the batch\n",
    "                batch_output = self.forward(batch_X)\n",
    "                batch_loss = np.mean(((batch_output - batch_y)/batch_y) ** 2)\n",
    "                train_loss_history.append(batch_loss)\n",
    "\n",
    "                #print(f'np.max(train_loss_history) = {np.max(train_loss_history)}')\n",
    "\n",
    "                self.backward(batch_X, batch_y, learning_rate)\n",
    "\n",
    "            # Forward pass and loss calculation for validation data\n",
    "            val_output = self.forward(X_val)\n",
    "            val_loss = np.mean((val_output - y_val) ** 2)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {batch_loss:.10f}, Val Loss: {val_loss:.10f}\")\n",
    "\n",
    "        return train_loss_history, val_loss_history\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "X = training_data[['height', 'wave_length']].values\n",
    "y = training_data.speed.values.reshape(-1, 1) \n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "num_epochs = 100000\n",
    "learning_rate = 0.000000000001\n",
    "#learning_rate = 0.000000000000000001\n",
    "#learning_rate = 10e-6\n",
    "batch_size = 64\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "train_loss_history, val_loss_history = network.train(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 45384.8641\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>wave_length</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78599.688827</td>\n",
       "      <td>1927.337789</td>\n",
       "      <td>54.855918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3508.728292</td>\n",
       "      <td>15221.672338</td>\n",
       "      <td>145.873054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86448.282139</td>\n",
       "      <td>16151.549318</td>\n",
       "      <td>158.800426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91334.040209</td>\n",
       "      <td>47468.784789</td>\n",
       "      <td>272.237925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77957.635081</td>\n",
       "      <td>29367.526137</td>\n",
       "      <td>214.130362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>48084.321176</td>\n",
       "      <td>2020.466097</td>\n",
       "      <td>56.165594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3678.472520</td>\n",
       "      <td>76407.374015</td>\n",
       "      <td>187.147094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>54015.980010</td>\n",
       "      <td>58781.496225</td>\n",
       "      <td>302.942840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>81416.981745</td>\n",
       "      <td>77626.967267</td>\n",
       "      <td>348.136901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>66976.730895</td>\n",
       "      <td>5274.240477</td>\n",
       "      <td>90.745382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           height   wave_length       speed\n",
       "0    78599.688827   1927.337789   54.855918\n",
       "1     3508.728292  15221.672338  145.873054\n",
       "2    86448.282139  16151.549318  158.800426\n",
       "3    91334.040209  47468.784789  272.237925\n",
       "4    77957.635081  29367.526137  214.130362\n",
       "..            ...           ...         ...\n",
       "995  48084.321176   2020.466097   56.165594\n",
       "996   3678.472520  76407.374015  187.147094\n",
       "997  54015.980010  58781.496225  302.942840\n",
       "998  81416.981745  77626.967267  348.136901\n",
       "999  66976.730895   5274.240477   90.745382\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "training_data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     86\u001b[0m network \u001b[38;5;241m=\u001b[39m ShallowReLUNetwork(input_size, hidden_size, output_size)\n\u001b[0;32m---> 87\u001b[0m train_loss_history, val_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Plot the training and validation loss\u001b[39;00m\n\u001b[1;32m     90\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "Cell \u001b[0;32mIn[272], line 47\u001b[0m, in \u001b[0;36mShallowReLUNetwork.train\u001b[0;34m(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m     batch_indices \u001b[38;5;241m=\u001b[39m indices[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     46\u001b[0m     batch_X, batch_y \u001b[38;5;241m=\u001b[39m X_train[batch_indices], y_train[batch_indices]\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Calculate loss for training and validation data\u001b[39;00m\n\u001b[1;32m     50\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(X_train, y_train)\n",
      "Cell \u001b[0;32mIn[272], line 26\u001b[0m, in \u001b[0;36mShallowReLUNetwork.backward\u001b[0;34m(self, X, y, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, learning_rate):\n\u001b[0;32m---> 26\u001b[0m     z2, a1, z1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m     27\u001b[0m     dLoss_dZ2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (z2 \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m/\u001b[39m y\n\u001b[1;32m     28\u001b[0m     dLoss_dW2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a1\u001b[38;5;241m.\u001b[39mT, dLoss_dZ2)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = {\n",
    "            'W1': np.random.randn(input_size, hidden_size) * np.sqrt(2 / input_size),\n",
    "            'W2': np.random.randn(hidden_size, output_size) * np.sqrt(2 / hidden_size)\n",
    "        }\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        z1 = np.dot(X, self.weights['W1'])\n",
    "        a1 = self.relu(z1)\n",
    "        z2 = np.dot(a1, self.weights['W2'])\n",
    "        return z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        z2, a1, z1 = self.forward(X)\n",
    "        dLoss_dZ2 = 2 * (z2 - y) / y\n",
    "        dLoss_dW2 = np.dot(a1.T, dLoss_dZ2)\n",
    "        dLoss_dA1 = np.dot(dLoss_dZ2, self.weights['W2'].T)\n",
    "        dLoss_dZ1 = dLoss_dA1 * (a1 > 0)\n",
    "        dLoss_dW1 = np.dot(X.T, dLoss_dZ1)\n",
    "        self.weights['W2'] -= learning_rate * dLoss_dW2\n",
    "        self.weights['W1'] -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the training data indices\n",
    "            indices = np.random.permutation(len(X_train))\n",
    "\n",
    "            # Perform mini-batch gradient descent\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                batch_X, batch_y = X_train[batch_indices], y_train[batch_indices]\n",
    "                self.backward(batch_X, batch_y, learning_rate)\n",
    "\n",
    "            # Calculate loss for training and validation data\n",
    "            train_loss = self.calculate_loss(X_train, y_train)\n",
    "            val_loss = self.calculate_loss(X_val, y_val)\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        return train_loss_history, val_loss_history\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "        output = self.forward(X)\n",
    "        loss = np.mean(((output - y) / y) ** 2)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"water_waves_training_data.csv\")\n",
    "\n",
    "# Extract input features (height and wave_length) and target variable (speed)\n",
    "X = data[['height', 'wave_length']].values\n",
    "y = data['speed'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and validation sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_epochs = 100000\n",
    "learning_rate = 0.0000000000000000001\n",
    "#learning_rate = 0.000000000001\n",
    "#learning_rate = 10e-6\n",
    "batch_size = 32\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "train_loss_history, val_loss_history = network.train(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "# Set y-axis limits\n",
    "#plt.ylim(0, max(max(train_loss_history), max(val_loss_history)) * 1.1)  # 10% buffer\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "train_accuracy = np.mean((network.forward(X_train) > 0.5) == y_train)\n",
    "val_accuracy = np.mean((network.forward(X_val) > 0.5) == y_val)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['Training', 'Validation'], [train_accuracy, val_accuracy])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the network on the validation set\n",
    "val_output = network.forward(X_val)\n",
    "print(f'p.mean(val_output-y_val) = {np.mean(val_output-y_val)}')\n",
    "print(f'np.mean(val_output) = {np.mean(val_output)}')\n",
    "print(f'np.mean(y_val) = {np.mean(y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to addendum but not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (4,4) not aligned: 1 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     57\u001b[0m network \u001b[38;5;241m=\u001b[39m ShallowReLUNetwork(input_size, hidden_size, output_size)\n\u001b[0;32m---> 58\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plot the loss history\u001b[39;00m\n\u001b[1;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(loss_history)\n",
      "Cell \u001b[0;32mIn[77], line 40\u001b[0m, in \u001b[0;36mShallowReLUNetwork.train\u001b[0;34m(self, X, y, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((output \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     38\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[77], line 24\u001b[0m, in \u001b[0;36mShallowReLUNetwork.backward\u001b[0;34m(self, X, y, learning_rate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, learning_rate):\n\u001b[1;32m     23\u001b[0m     dLoss_dZ2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz2 \u001b[38;5;241m-\u001b[39m y\n\u001b[0;32m---> 24\u001b[0m     dLoss_dW2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLoss_dZ2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     dLoss_dA1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2, dLoss_dZ2)\n\u001b[1;32m     26\u001b[0m     dLoss_dZ1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m dLoss_dA1\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,1) and (4,4) not aligned: 1 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ShallowReLUNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Initialize weights randomly with Xavier initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2 / input_size)\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2 / hidden_size)\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1)\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        return self.z2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        dLoss_dZ2 = self.z2 - y\n",
    "        dLoss_dW2 = np.dot(dLoss_dZ2, self.a1)\n",
    "        dLoss_dA1 = np.dot(self.W2, dLoss_dZ2)\n",
    "        dLoss_dZ1 = (self.a1 > 0).T * dLoss_dA1\n",
    "        dLoss_dW1 = np.dot(dLoss_dZ1, X)\n",
    "\n",
    "        self.W2 -= learning_rate * dLoss_dW2 \n",
    "        self.W1 -= learning_rate * dLoss_dW1\n",
    "\n",
    "    def train(self, X, y, num_epochs, learning_rate):\n",
    "        loss_history = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = np.mean((output - y) ** 2)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = ShallowReLUNetwork(input_size, hidden_size, output_size)\n",
    "loss_history = network.train(X, y, num_epochs, learning_rate)\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
